{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Yass - Yet Another Simple Scraper","text":"<p>Yass is a microframework that makes it easier to retrieve information from APIs and regular websites.</p> <p>Yass, unlike complex projects like Scrapy or simple libraries like BeautifulSoup, is extremely easy to use due to the unification of the information extraction process and at the same time has quite a wide range of functionality.</p> <p>Unstable API</p> <p>Currently, Yass is at the beginning of its development - there may still be undetected bugs and frequent changes in interfaces. In this regard, it is highly not recommended to use it in production.</p>"},{"location":"#why-use-yass","title":"Why use Yass?","text":"<ul> <li> <p> Asynchronous execution</p> <p>Yass is built on top of asyncio and asynchronous libraries, which significantly speeds up your code in the context of I/O operations.</p> </li> <li> <p> Unified architecture</p> <p>With Yass, there is no need to continuously customize the data scraping process. From project to project, you will have a single, transparent architecture.</p> </li> <li> <p> Multiple backend support</p> <p>Yass allows you to route data to any backend: s3-like storage, database, network file system, broker/message bus, etc.</p> </li> <li> <p> Flexible configuration options</p> <p>Yass allows the user to choose what to do with the data: hold it in memory until a certain critical value accumulates, or immediately send it to the backend, perform pre-processing, or leave it as is.</p> </li> </ul>"},{"location":"#installation","title":"Installation","text":"<p>Installation is as simple as:</p> <p><code>pip install yass</code></p> Dependencies <p>The list of core Yass dependencies is represented by the following libraries:</p> <pre><code>- aiohttp\n- aioitertools\n- fsspec\n- more-itertools\n- regex\n- uvloop (for Unix platforms)\n- yarl\n- dateparser\n- beartype\n</code></pre>"},{"location":"about/concepts/","title":"Yass Components","text":"<p>This page provides brief definitions of Yass components to provide a better understanding of exactly how Yass works under the hood.</p> <p>Although Yass is made up of many parts\u2014main classes, service classes, utilities, and functions\u2014only a few of them form the foundation of a working application.More detailed information about each component can be found in the Tutorials section or in the API description of each module.</p>"},{"location":"about/concepts/#resources","title":"Resources","text":"<p>Key component. A resource is nothing more than a data source located on the network. This could be a third-party API or an API owned by your organization, or simply a website that hosts the information you need.</p> Stay ethical <p>The Yass developer does not encourage or condone attempts to borrow information from a resource against the will of the resource owner. Therefore, if in the process of scraping data you encounter powerful resistance from the source, I strongly recommend that you think about whether you are doing something that is acceptable to the owner of the resource and whether it is worth the potential damage for both parties.</p> <p>Functionality limitation</p> <p>Currently only working with the API is available. More uses of Yass will become available in the future.</p> <p>As a matter of fact, if you do not declare a Resource in the code, then no work will begin :) The resource, as a central entity, performs the following functions:</p> <ul> <li>fixes the entry point to the data source and stores authorization information;</li> <li>allows you to create queries to a data source and stores information about them;</li> <li>defines restrictions on the data source, such as the number of requests per second, the minimum delay between requests, the maximum time to wait for a response;</li> <li>stores triggers that allow you to interrupt resource processing based on specified criteria.</li> </ul>"},{"location":"about/concepts/#requests","title":"Requests","text":"<p>A lower level component that is directly involved in the information retrieval process. If we generalize the functionality of the Request classes, we can say that at the level of each specific request the following is determined:</p> <ul> <li>how to generate links to send a network request, thereby defining the data source section that Yass will work with;</li> <li>what input data we expect to receive and in what format we plan to upload it;</li> <li>where we want to store the data obtained as a result of the execution of this request;</li> <li>whether additional processing of this request is needed.</li> </ul> <p>Thus, top-level information about how to work with a data source is recorded in the Resource class, and more applied details, without which it is impossible to correctly extract data from the source, are defined in Request.</p> <p>Several entities are also associated with Requests (I/O context, pipelines), which are service entities in relation to it, and therefore more detailed information about them is provided in other sections of the documentation.</p>"},{"location":"about/concepts/#data-collectors","title":"Data collectors","text":"<p>Data collectors are the workhorses that pull links from Requests, retrieve data from the source, wait for the data to be converted, and pass it on for storage/further transmission. For each request, one data collector is created, which operates concurrently in the event loop.</p> <p>The data collector's work begins by waiting for the current time to be scheduled to work with the resource. Once the data collector has started, it repeats the 'wait-receive' loop endlessly until an unexpected error occurs or the user cancels the corresponding instance of the class (1).</p> <ol> <li> There is currently no way to stop data collectors unless an unexpected error occurs. The first stable version of Yass will feature a cli interface that allows you to selectively stop the selected data collector.</li> </ol> <p>Typically, you won't have to instantiate data collectors yourself, since they are generated automatically by the application class when the application starts. However, in the future it is planned to add an interface with the ability to receive an instance of the created data collector.</p>"},{"location":"about/concepts/#storages","title":"Storages","text":"<p>The repository concludes the overview of Yass core components.</p> <p>The storage ensures the transfer of data to the selected backend, and the backend can be anything - persistent storage or some kind of message broker, data processing platform. The main role of this entity is to summarize information about registered backends and provide unified interfaces for working with them. Inextricably linked with storage is the concept of an engine - this is the object through which Yass establishes a connection with the backend and transmits data. The essence of the engine is that it transfers a similar object well to SqlAlchemy.</p> <p>In other words, Storage is an interface to storage deployed outside the Yass loop.</p> <p>Although this family of classes has public interfaces, you don't actually have to use them when using Yass - they are all baked into template methods of other classes involved in data scraping, and are applied \"automatically\". These interfaces can be useful if you plan to combine Yass with other solutions within your architecture.</p>"},{"location":"about/concepts/#whats-next","title":"What's next?","text":"<p>Once you are familiar with the key components, it is best to study the Study Guide. It clearly shows the process of preparing an application to work with the Financialmodelingprep API. Thanks to them for the opportunity to provide a more meaningful example to Yass users<sup>1</sup>!</p> <p>Something else about working with FMP</p> <p>FMP also has its own SDK for working with their API. In case you are interested in working with this resource, it is here.</p> <ol> <li> <p>Financialmodelingprep provides financial information about public companies via an API that is free up to 250 calls per day.\u00a0\u21a9</p> </li> </ol>"},{"location":"about/tutorial/step_1/","title":"Let's get started","text":""},{"location":"about/tutorial/step_1/#reate-resource","title":"\u0421reate resource","text":"<p>Let's assume that we are interested in information about income and expenses, balance sheets for a small list of companies. Having visited the sections we need on the FMP website and studied the pattern of link formation, we will configure the resource and requests to it.</p>"},{"location":"about/tutorial/step_1/#create-core-class","title":"Create core class","text":"<p>Declaring the necessary constants:</p> <pre><code>from os import getenv\nfrom yass.resources.api import ApiResource, EndpointPath, SimpleEORTrigger\nfrom yass import EntryPoint\n\nAPI_KEY: str | None = getenv(\"FMP_API\")\nAPI_URL = \"https://financialmodelingprep.com/api/v3\"\n\nTICKERS: list[str] = [\"AAPL\", \"MSFT\", \"AMZN\", \"NVDA\", \"TSLA\",\"MA\", \"PG\"]\nHEADERS = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:127.0) Gecko/20100101 Firefox/127.0\", \"Accept-Encoding\": \"gzip, deflate, br, zstd\"}\n</code></pre> <p>Creating an entry point into the application and register the resource:</p> About example <p>You can test Yass on a different API and with different parameters of all classes, not limited to what is presented in the Tutorial.</p> <pre><code>app = EntryPoint()\nfmp_api: ApiResource = app.define_resource(resource_type='api', url=API_URL)\nfmp_api.request_timeout = 60\nfmp_api = fmp_api.configure(extra_headers=HEADERS, max_batch=2, delay=5, eor_triggers=[SimpleEORTrigger(12)])\n</code></pre> <p>What did we just do? We declared an API resource, set a maximum timeout for requests associated with this resource, delay and also enriched requests to this resource with the headers we needed.</p> <p>Let's go through a few key parameters.</p> <p>Max_batch parameter is responsible for how many requests can be sent to a resource at the same time. In this case, this limit is divided between all working data collectors. If we needed to process three parts of the FMP API at the same time, one of the data collectors would be idle until the other one finished its work, since the quota of two requests was used up by the first two fastest data collectors.</p> <p>And vice versa, if only one request to a resource were created with such a limit, then the only data collector would scoop up the entire available quota and send two requests at a time to the resource.</p> <p>When setting this parameter, we suggest taking into account the rate limit and restrictions on parallel requests for a specific resource.</p> <p>The eor_trigger parameter is nothing more than an object that detects the end of payload in a resource or the moment at which it is necessary to stop processing the resource even if there is a payload.</p> <p>At the moment, several trigger options are implemented for the resource API. Sometimes we don\u2019t know how much data we can get from a resource, or we are limited by the number of requests per day, as in our case, so it is possible to combine different triggers. When combining triggers, a pessimistic approach applies - resource processing will stop as soon as at least one trigger fires.</p> <p>In our example, we use a simple trigger that limits work with a resource by the number of requests to it. Moreover, we mean precisely the number of requests, and not the cycles of sending requests/receiving responses.</p> <p>Trigger classes do not store information about previous test results. Therefore, if there is some kind of global restriction on a resource, as in our case (limit of 250 requests per day), it needs to be implemented through the totality of all available Yass limiting objects (for example, start collecting data only once a day for the entire limit or split the total available amount requests by number of starts and requests).</p> <p>For our example, we set a limit of 12 requests (1) per run.</p> <ol> <li> This configuration is provided for informational purposes only and is in no way calculated through available resource quotas.</li> </ol>"},{"location":"about/tutorial/step_1/#registering-endpoints","title":"Registering endpoints","text":"<p>Let's continue preparing our application and let\u2019s designate the endpoints that we will process in the API.</p> <pre><code>income_endpoint: EndpointPath = fmp_api.add_endpoint('income')\nincome_endpoint.add_fix_part(\"income-statement\", 0)\nincome_endpoint.add_mutable_parts(TICKERS)\n\nbalance_endpoint: EndpointPath = fmp_api.add_endpoint('balance')\nbalance_endpoint.add_fix_part('balance-sheet-statement')\nbalance_endpoint.add_mutable_parts(TICKERS)\n</code></pre> <p>Endpoint objects allow us to form sort of \u201csubsections\u201d of a resource, like chapters in books, and are needed to correctly expand the base url of a resource. Subsequently, a request object will be created for each such endpoint.</p> <p>As you can see from the names of the methods, we have added a fixed part of the expanded url - it will always be the same when generating links - and a variable part, which will change after the query filed is exhausted for each variable part.</p> <p>The placement of link parts in Endpoint objects can be controlled using the optional prior parameter. If we need the part of the link to be the very first, we will set its prior to one.</p> <p>You can see how many sections are registered in the endpoint using the last_prior attribute.</p> <pre><code>balance_endpoint.add_mutable_parts(TICKERS, prior=1)\nprint(balance_endpoint.last_prior) # Display 1.\n</code></pre> <p>It looks like we are done with the formation of the resource, now let\u2019s move on to an equally important part, namely the formation of the I/O environment.</p>"},{"location":"about/tutorial/step_2/","title":"Input and output","text":"<p>Since we are working with a resource to extract data, it would not hurt us to formulate answers to several questions:</p> <ul> <li>what types of data we process;</li> <li>how we process data;</li> <li>where will we store them and whether we will store them at all;</li> <li>will we somehow additionally process the data.</li> </ul> <p>And the answers to most of the questions are provided by the contentio module and the concept of I/O contexts. In the practical part, let\u2019s not get into the details of the Yass architecture and let\u2019s get down to business.</p>"},{"location":"about/tutorial/step_2/#registering-data-formats","title":"Registering data formats","text":"<p>To process any data, we need to define its format and handler functions, which we will do now. We know that the FMP API gives us data in json format. We will save the data in csv format.</p> <pre><code>from yass import contentio\nimport polars as pl\n\ncontentio.create_datatype(\n    format_name=\"json\",\n    input_func=pl.read_json,\n    output_func=pl.DataFrame.write_json,\n)\n\ncontentio.create_datatype(\n    format_name=\"csv\",\n    input_func=pl.read_csv,\n    output_func=pl.DataFrame.write_csv,\n)\n</code></pre> <p>Using the create_datatype module-level function, we declared two data types - csv and json - and also assigned handler functions to them using the wonderful Polars library. Thanks to Polars, we can seamlessly convert json data to csv, since both data types are schema-dependent and can be described in terms of a dataframe.</p> <p>About data types and their handlers</p> <p>The system of data types and their processing is the weakest part of the Yass API. At the moment, it is necessary to explicitly declare types and handlers assigned to them, but this creates the risk of impossibility of converting structured and semi-structured data from one format to another, despite the fact that they are all schema-dependent and have explicit polymorphism, and also requires the introduction of adapter objects between all compatible data types.</p> <p>The most likely solution will be to create data type presets in Yass and use universal libraries like Polars for structured data and Pillow type for blob-like data. Subsequently, the user will not have to manage the composition of data types and their handlers, which will also relieve him of responsibility for the backward compatibility of handlers.</p>"},{"location":"about/tutorial/step_2/#registration-of-storage","title":"Registration of storage","text":"<p>Now we will determine where we will store the data. We will choose S3 object storage. Let's cook it.</p> <pre><code>S3_KWARGS = {\n    \"endpoint_url\": getenv(\"S3_ENDPOINT\"),\n    \"key\": getenv(\"S3_KEY\"),\n    \"secret\": getenv(\"S3_SECRET\"),\n    \"client_kwargs\": {\n      'region_name': getenv(\"S3_REGION\")\n   }\n}\n\nstorage: FsBlobStorage = app.define_storage(storage_type=\"blob\")\nstorage = storage.configure(\n    engine_proto=\"s3\",\n    engine_params=S3_KWARGS,\n    bufferize=True,\n    limit_type=\"count\",\n    limit_capacity=3,\n)\n</code></pre> <p>In this piece of code, we received the parameters we needed to initialize the storage and configured it. Let's also go over some parameters.</p> <p>Engine_proto is the key under which this or that engine of a certain storage class is registered. Under the hood of the storage classes, a factory is triggered that returns a storage engine object, through which a connection is established with the actual backend and all sorts of manipulations are carried out with it. If the engine is not registered, we will receive the corresponding error.</p> <p>Bufferize is a switch - if True, then all data will be pre-buffered in memory and unloaded only when the set limit is exceeded. Otherwise, the data will be immediately transferred to the backend, regardless of whether some kind of limit is set or not.</p> <p>The Limit Type is nothing more than the key by which one or another Limit class is registered. These are special triggers that determine the moment of uploading data to the backend according to some criterion, for example, the number of elements in the data collector buffer, memory occupied by the data. Again, a factory is triggered under the hood, which, having detected the required implementation using the key, returns an object.</p> About polymorphism in Yass <p>At the moment, users cannot register their own limit types and storage engines; this is an internal Yass implementation detail and will most likely not be available in public in the future. If your practice has some special use case and the current capabilities of Yass are not enough, you can open an issue for its creation.</p>"},{"location":"about/tutorial/step_2/#creating-context-objects","title":"Creating context objects","text":"<p>Finally, we can define I/O contexts for each scheduled query.</p> <pre><code>income_context: contentio.IOContext = contentio.create_io_context(\n    in_format=\"json\", out_format=\"csv\", storage=storage\n)\n\nbalance_context: contentio.IOContext = contentio.create_io_context(\n    in_format=\"json\", out_format=\"csv\", storage=storage\n)\n</code></pre> <p>Theoretically, if we are:</p> <ul> <li>not going to transform the original data;</li> <li>keys to be stored in memory for all requests to a resource will be formed according to the same pattern;</li> <li>data will be uploaded to the same backend</li> </ul> <p>then we don't need to register multiple contexts. However, our history will develop according to a different scenario.</p>"},{"location":"about/tutorial/step_2/#augmenting-the-context-object","title":"Augmenting the context object","text":"<p>IOContext objects are key during the data processing phase. In addition to the fact that with their help we record what we are going to receive, what to return and where to store it, they also allow us to formulate a pattern for forming a path for storing data (or, for example, table names if we are going to enter data into the database) and enrich/ modify data before it is stored in memory or flushed to the backend.</p> <p>As a matter of fact, we are now mapping out the path formation pattern behind each context, and also designing a pipeline for one of the contexts.</p>"},{"location":"about/tutorial/step_2/#path-generator","title":"Path generator","text":"<p>First, we need to create path generator objects. These objects represent a kind of collection that processes PathSegment objects. These segments are nothing more than parts of what we will end up with.</p> <p>Warning</p> <p>When forming paths/tables, etc. you need to consider the storage structure of the data destination. Registering redundant segments may result in a level of nesting that is not supported by the end backend.</p> <p>Well, just do it.</p> <pre><code>i_pathgenerator: contentio.PathTemplate = income_context.attache_pathgenerator()\ni_pathgenerator.add_segment(\"_\", 1, [\"fmp_api\"])\ni_pathgenerator.add_segment(\"_\", 2, [\"income\", date.today, time])\ni_pathgenerator.add_segment(\"_\", 3, [\"test\"])\n\nb_pathgenerator: contentio.PathTemplate = balance_context.attache_pathgenerator()\nb_pathgenerator.add_segment(\"_\", 1, [\"fmp-api\"])\nb_pathgenerator.add_segment(\"_\", 2, [\"balance\", date.today, time])\nb_pathgenerator.add_segment(\"_\", 3, [\"test\"])\n</code></pre> <p>So what's going on here:</p> <ul> <li>we attached a path generator to each context object (if it goes down one level - keys for mapping);</li> <li>to each path generator we add segments: the first is the name of the resource, the second is the short name of the endpoint, the current date and timestamp, the third is the string \u201ctest\u201d.</li> </ul> <p>As you may have noticed, the number of elements in one segment is not limited and an element can be a callable object.</p> <ul> <li>the dash in the very first argument is a concatenator. It is this symbol that will be used to combine elements of one segment;</li> <li>we also use the second argument to indicate the order in which the segments will be arranged.</li> </ul> <p>Note</p> <p>In theory, the order of segments can be fixed simply by adding segments in the desired order. However, if we first generate temporary keys, and then modify the path generator on the fly in the pipeline to obtain the final storage path, then the priority argument allows us to make such an operation much more flexible and faster using existing tools without writing additional logic.</p> <p>This note applies to all Yass entities whose constructors and methods take as an argument a priority value or something similar to that value. Probably in future releases in some cases such arguments will be excluded or the functionality using these arguments will be changed.</p> <p>You can check which line will be rendered with the given parameters as follows:</p> <pre><code>i_pathgenerator.render_path()\n</code></pre>"},{"location":"about/tutorial/step_2/#charging-pipelines","title":"Charging pipelines","text":"<p>Suppose among the information related to company income in the FMP API, we only need identifying fields, coefficients, and we also need to add our own custom indicator coefficient. And additionally, we will add the record creation date for each row. The tasks of data conversion and object modification are solving in Yass using pipelines.</p> <p>The essence of how pipelines work is simple - it registers a handler function and applies it to incoming data, which is in serialized form before uploading to the backend. All handlers run in a separate thread and do not block the Yass execution thread.</p> IO bound and CPU bound tasks <p>Yass's asynchronous capabilities and Python's concurrency model are great for I/O and small CPU workloads. However, if you need to implement CPU-heavy processing of tasks, you should use a non-standard solution in your pipelines, which can be guaranteed to execute the task on a separate core without connection with the GIL. A large number of CPU tasks alone will significantly reduce the performance of Yass only due to the nature of Python working in a multiprocessor environment.</p> <p>We implement everything previously said in simple code.</p> <pre><code>from polars import DataFrame\n\nincome_pipeline: contentio.IOBoundPipeline = income_context.attache_pipeline()\n\n@income_pipeline.step(1)\ndef append_interest_rate_ratio(data: DataFrame) -&gt; DataFrame:\n    new_frame = data.with_columns(\n        (pl.col(\"interestExpense\") / pl.col(\"revenue\") * 100).round(2).alias(\"InterestRate\")\n        )\n    return new_frame\n\n@income_pipeline.step(2)\ndef get_only_income_ratio(data: DataFrame) -&gt; DataFrame:\n    needed_fields = [\"date\", \"symbol\", \"fillingDate\", \"calendarYear\", \"period\", \"grossProfitRatio\", \"operatingIncomeRatio\", \"netIncomeRatio\", \"InterestRate\"]\n    new_frame = data.select(needed_fields)\n    return new_frame\n\n@income_pipeline.step(3)\ndef insert_metadata(data: DataFrame) -&gt; DataFrame:\n    created_at = pl.Series(\n        \"created_at\", [datetime.now().date()] * data.shape[0], pl.Date\n    )\n    new_frame = data.insert_column(data.shape[1], created_at)\n    return new_frame\n\nincome_pipeline.show_pipeline()\n</code></pre> <p>Our pipeline is ready. In pipelines we can carry out any operations, including compressing data into one object, completely changing the structure of a data object (for example, parsing a downloaded doc file, wrapping the necessary data in json and putting this json in the buffer instead of the original object), receiving additional data from other services and merge them with the original object. Everything is limited only by your imagination, needs and serialization capabilities of the functions and tools you use.</p> Mmm, why are there steps here? <p>Unfortunately, pipelines are also a weak part of the Yass API. There are several problems at once: this is access to global objects if you need to interact with them, and the risk of a large overproduction of threads, and there is no state storage. In the future, it is planned to eliminate these shortcomings, including the ability to save the state of the pipeline when errors occur and reload it from where it stopped in runtime.</p> <p>This is part of a lot of work to come and after hammering away at the simpler components of Yass, the code and functionality of the pipelines will be polished. The step method is a tiny piece of the future API.</p> <p>Now the final part remains. Let's get to it.</p>"},{"location":"about/tutorial/step_3/","title":"Creating and run requests to a resource","text":"<p>In general, all that\u2019s left to do is create requests and schedule them. Let's get started.</p> <pre><code>from yass.scheduling import TimeCondition\n\ntime_interval_income: ActionCondition = TimeCondition(\n    period=1, start_time=\"11:22\", end_time=\"22:00\", frequency=0\n)\ntime_interval_balance: ActionCondition = TimeCondition(\n    period=1, start_time=\"11:22\", end_time=\"22:00\", frequency=0\n)\n</code></pre> <p>We have just declared two timers. Timers belong to the trigger family that are used in the active part of Yass. Let's talk about what will happen based on the current timer parameters: our activity starts at 11.22, every day (since we transmitted one) and once a day (since the frequency parameter is set to zero); the time after which the waiting period begins is 22.00. If we launch our application after 22.00, it will wait until the next day to start crawling the resource.</p> <p>If we wanted scheduling to be carried out by days of the week, then we would need to pass a tuple with the required days of the week in ISO format (numbers from 1 to 7).</p> Expected API changes <p>In future releases, it is planned that scheduling will be set at the request class level through the appropriate method, without the need to import the class from the module. This is also the part of the Yass API that will be expanded - there will be new active triggers that allow you to flexibly organize the launch of data collectors not only by time and dates, but also by other criteria.</p> <p>Actually, we are all ready to create request objects and start collecting data.</p> <pre><code>report_params = {\"period\": \"annual\", \"limit\":5, \"apikey\": API_KEY}\n\nincome_query: ApiRequest = fmp_api.make_query(\n    \"income_statement\",\n    \"income\",\n    fix_params=report_params,\n    collect_interval=time_interval_income,\n    io_context=income_context,\n    has_pages=False,\n)\n\nbalance_query: ApiRequest = fmp_api.make_query(\n    \"balance_sheet\",\n    balance_endpoint,\n    fix_params=report_params,\n    collect_interval=time_interval_balance,\n    io_context=balance_context,\n    has_pages=False,\n)\n\napp.run()\n</code></pre> <p>After processing requests is complete, we can see what we have in storage using module-level functions.</p> <pre><code>from yass.storages import blob\n\ncontent_list = blob.ls_storage(storage.engine, \"fmp-api\")\nprint(content_list)\ncontent = blob.read(storage.engine, content_list[0])\nprint(content)\n</code></pre> <p>That's all for now. I hope everything worked out for you ;)</p>"},{"location":"api/about_section/","title":"About the API section","text":""},{"location":"api/about_section/#about-section","title":"About section","text":"<p>This section provides a description of the main and auxiliary modules of Yass. A number of functions and classes are not intended for direct use by users, but for demonstration purposes, private utility functions are exposed as public.</p> <p>Private class methods that are not essential to understanding the code are not covered in this section.</p>"},{"location":"api/api_data_collectors/","title":"Implementations","text":""},{"location":"api/api_data_collectors/#core-classes","title":"Core classes","text":""},{"location":"api/api_data_collectors/#yass.data_collectors.ApiDataCollector","title":"<code>ApiDataCollector(query: ApiRequest, resource: ApiResource)</code>","text":"<p>             Bases: <code>BaseDataCollector</code></p> <p>Data Collector designed for API resources. In addition to the attributes inherited from the base class (see BaseDataCollector for more details), ApiDataCollector also parses the resource for additional headers for requests, restrictions on the number of requests, and records triggers set for the resource.</p> <p>Attributes:</p> Name Type Description <code>delay</code> <code>int | float</code> <p>delay before sending requests.</p> <code>timeout</code> <code>int | float</code> <p>waiting time for a response from the data source.</p> <code>collect_trigger</code> <code>ActionCondition</code> <p>a trigger, the firing of which allows you to begin processing the data source.</p> <code>eor_status</code> <code>bool</code> <p>the status of no payload in the data source.</p> <code>_write_channel</code> <code>ContentQueue</code> <p>a buffer in memory in which data is stored before uploading to the backend.</p> <code>url_series</code> <code>AsyncGenerator</code> <p>a link generator created by a Request instance.</p> <code>pipeline</code> <code>IOBoundPipeline</code> <p>an instance of the pipeline class associated with a request that is processed by the data collector.</p> <code>input_format</code> <code>str</code> <p>format of incoming data.</p> <code>output_format</code> <code>str</code> <p>the format in which the data should be saved.</p> <code>path_producer</code> <code>PathTemplate</code> <p>data path generator.</p> <code>client_factory</code> <code>ClientSession</code> <p>session object factory. The aiohttp library class is used.</p> <code>batcher</code> <code>BatchCounter</code> <p>atomic request limit counter per second.</p> <code>headers</code> <code>dict</code> <p>additional request headers, including authorization headers.</p> <code>eor_checker</code> <code>EORTriggersResolver</code> <p>an instance of the EOR resolver class. Used to check for the presence of a payload in the query results.</p> <code>current_bs</code> <code>int</code> <p>the allowed number of simultaneous requests to the data source.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>ApiRequest</code> <p>an instance of the request to the resource for which the data collector is being created.</p> required <code>resource</code> <code>ApiResource</code> <p>a resource from which additional information is retrieved to initialize the data collector.</p> required Source code in <code>src\\yass\\data_collectors\\api.py</code> <pre><code>def __init__(self, query: ApiRequest, resource: ApiResource):\n    \"\"\"\n    Args:\n        query (ApiRequest): an instance of the request to the resource for which the data collector is being created.\n        resource (ApiResource): a resource from which additional information is retrieved to initialize the data collector.\n    \"\"\"\n    super().__init__(resource, query)\n    self.client_factory = ClientSession\n    self.batcher: BatchCounter = resource.batch\n    self.headers: dict = resource.extra_headers\n    self.eor_checker: EORTriggersResolver = EORTriggersResolver(resource)\n    self.current_bs: int = 0\n</code></pre>"},{"location":"api/api_data_collectors/#yass.data_collectors.ApiDataCollector.process_requests","title":"<code>process_requests(urls: list[str]) -&gt; list[bytes]</code>  <code>async</code>","text":"<p>The method sends requests to the list of urls passed as a parameter. All requests are processed asynchronously. During URL processing, the presence of \u201cbad\u201d response codes is monitored. This method also monitors the fact that the resource has expired.</p> <p>Parameters:</p> Name Type Description Default <code>urls</code> <code>list[str]</code> <p>list of urls to process. The list of links is generated in a size that is acceptable for the current load on the resource.</p> required <p>Raises:</p> Type Description <code>RuntimeError</code> <p>thrown if a response code from group 2xx is received.</p> <p>Returns:</p> Name Type Description <code>list</code> <code>bytes</code> <p>batch of content in byte representation.</p> Source code in <code>src\\yass\\data_collectors\\api.py</code> <pre><code>async def process_requests(self, urls: list[str]) -&gt; list[bytes]:\n    \"\"\"\n    The method sends requests to the list of urls passed as a parameter. All requests are\n    processed asynchronously. During URL processing, the presence of \u201cbad\u201d response codes\n    is monitored. This method also monitors the fact that the resource has expired.\n\n    Args:\n        urls (list[str]): list of urls to process. The list of links is generated in a size that is acceptable for the current load on the resource.\n\n    Raises:\n        RuntimeError: thrown if a response code from group 2xx is received.\n\n    Returns:\n        list (bytes): batch of content in byte representation.\n    \"\"\"\n    if len(urls) &gt; 0:\n        session: ClientSession\n        async with self.client_factory(\n            timeout=aiohttp.ClientTimeout(self.timeout),\n            headers=self.headers,\n            json_serialize=orjson.dumps,  # type:ignore\n        ) as session:\n            tasks: list[\n                Coroutine[Awaitable[Any], None, ClientResponse]\n            ] = [\n                session.get(url)\n                for url in urls  # type: ignore\n            ]\n            self.current_bs = self.batcher.recalc_limit(self.current_bs)\n            responses: list[ClientResponse | BaseException] = await gather(\n                *tasks, return_exceptions=True\n            )\n        error_resp: ClientResponse | BaseException\n        # FIXME: \u0410 \u044d\u0442\u043e \u043d\u043e\u0440\u043c\u0430 \u0432\u0430\u0449\u0435?\n        responses_only: list[ClientResponse] = [\n            r for r in responses if not isinstance(r, TimeoutError)\n        ]  # type: ignore\n        for error_resp in filterfalse(\n            lambda x: x.status in list(range(200, 299, 1)), responses_only\n        ):\n            msg: str = (await error_resp.content.read()).decode()\n            raise RuntimeError(error_resp.url, error_resp.headers, msg)\n    else:\n        self.eor_status = True\n        return []\n    contents: list[bytes] = await gather(\n        *[resp.content.read() for resp in responses_only]\n    )\n    eor_check: list[bool] = self.eor_checker.eor_signal(\n        contents, responses_only\n    )\n    contents = list(compress(contents, eor_check))\n    self.eor_status: bool = not all(eor_check)\n    return contents\n</code></pre>"},{"location":"api/api_data_collectors/#yass.data_collectors.ApiDataCollector.start","title":"<code>start() -&gt; Task</code>  <code>async</code>","text":"<p>Entry point for running the data collector. The method starts the procedure for crawling the resource according to the parameters of the request sent to the data collector.</p> <p>Returns:</p> Name Type Description <code>Task</code> <code>Task</code> <p>task created for the start method. In other words, when the useful data in the resource runs out, the data collector will resume waiting for the conditions under which data parsing will begin again.</p> Source code in <code>src\\yass\\data_collectors\\api.py</code> <pre><code>async def start(self) -&gt; Task:\n    \"\"\"\n    Entry point for running the data collector. The method starts the procedure\n    for crawling the resource according to the parameters of the request sent to the data collector.\n\n    Returns:\n        Task: task created for the start method. In other words, when the useful data in the resource\n            runs out, the data collector will resume waiting for the conditions under which data\n            parsing will begin again.\n    \"\"\"\n    await self.collect_trigger.pending()\n    await self._write_channel.storage.launch_session()\n    self.current_bs: int = await self.batcher.acquire_batch()\n    rpp(\n        f\"\u0422\u0435\u043a\u0443\u0449\u0438\u0439 \u0440\u0430\u0437\u043c\u0435\u0440 \u0431\u0430\u0442\u0447\u0430 {self.current_bs}. \u041c\u0438\u043d\u0438\u043c\u0430\u043b\u044c\u043d\u044b\u0439 \u0440\u0430\u0437\u043c\u0435\u0440 \u0431\u0430\u0442\u0447\u0430 {self.batcher.min_batch}.\"\n    )\n    url_gen: AsyncGenerator[str, None] = self.url_series()\n    while True:\n        urls: list[str] = await take(self.current_bs, url_gen)\n        rpp(f\"\u041a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u043d\u044b\u0445 \u0441\u0441\u044b\u043b\u043e\u043a {len(urls)}\")\n        print(\"Urls \u0434\u043b\u044f \u043e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0438\")\n        print(urls)\n        start = int(time())\n        raw_content: list[bytes] = await self.process_requests(urls)\n        if len(raw_content) &gt; 0:\n            deser_content = tuple(\n                [\n                    deserialize(raw_bytes, self.input_format)\n                    for raw_bytes in raw_content\n                ]\n            )\n            if self.pipeline is not YassUndefined:\n                async with self.pipeline.run_transform(\n                    deser_content\n                ) as pipeline:\n                    deser_content = await pipeline\n            if deser_content:\n                prepared_content = tuple(\n                    (\n                        self.path_producer.render_path(self.output_format),\n                        dataset,\n                    )\n                    for dataset in deser_content\n                )\n            async with self._write_channel.block_state() as buf:\n                await buf.parse_content(prepared_content)\n        rpp(f\"\u041d\u043e\u0432\u044b\u0439 \u0440\u0430\u0437\u043c\u0435\u0440 \u0431\u0430\u0442\u0447\u0430 \u0441\u043e\u0441\u0442\u0430\u0432\u0438\u043b {self.current_bs}\")\n        end = int(time())\n        print(f\"\u0412\u0440\u0435\u043c\u044f \u043e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0438 \u0437\u0430\u043f\u0440\u043e\u0441\u043e\u0432 \u0441\u043e\u0441\u0442\u0430\u0432\u0438\u043b\u043e {end - start} \u0441\u0435\u043a\u0443\u043d\u0434\")\n        effect_delay: int | float = self.delay - (end - start)\n        rpp(f\"\u042d\u0444\u0444\u0435\u043a\u0442\u0438\u0432\u043d\u0430\u044f \u0437\u0430\u0434\u0435\u0440\u0436\u043a\u0430 \u0441\u043e\u0441\u0442\u0430\u0432\u0438\u043b\u0430 {effect_delay} \u0441\u0435\u043a\u0443\u043d\u0434.\")\n        rpp(f\"\u0420\u0435\u0441\u0443\u0440\u0441 \u0437\u0430\u043a\u043e\u043d\u0447\u0438\u043b\u0441\u044f? {self.eor_status}\")\n        if effect_delay &gt; 0:\n            await sleep(effect_delay)\n        if self.eor_status:\n            try:\n                await url_gen.asend(self.eor_status)  # type:ignore\n            except StopAsyncIteration:\n                rpp(\"\u041e\u0431\u0445\u043e\u0434 \u0440\u0435\u0441\u0443\u0440\u0441\u0430 \u0437\u0430\u0432\u0435\u0440\u0448\u0435\u043d.\")\n                self.eor_status = False\n                break\n    self.batcher.release_batch(self.current_bs)\n    coro = self.start()\n    return create_task(coro, name=self._name)\n</code></pre>"},{"location":"api/api_data_collectors/#service-classes-and-utilities","title":"Service classes and utilities","text":""},{"location":"api/api_data_collectors/#yass.data_collectors.EORTriggersResolver","title":"<code>EORTriggersResolver(resource: ApiResource)</code>","text":"<p>The class parses the status of all triggers set for a resource and returns an indicator for the end of the resource.</p> <p>Parameters:</p> Name Type Description Default <code>resource</code> <code>ApiResource</code> <p>the resource from which triggers will be retrieved. At the moment, such a resource can only be API resources.</p> required Source code in <code>src\\yass\\data_collectors\\api.py</code> <pre><code>def __init__(self, resource: ApiResource):\n    self.content_searchers: list[ApiEORTrigger] = list()\n    self.headers_searchers: list[ApiEORTrigger] = list()\n    self._resolve_searchers(resource.eor_triggers)\n</code></pre>"},{"location":"api/api_data_collectors/#yass.data_collectors.EORTriggersResolver.eor_signal","title":"<code>eor_signal(content: list[bytes], responses: list[ClientResponse]) -&gt; list[bool]</code>","text":"<p>Returns the resource end indicator for a batch of request results. Depending on the triggers installed on the resource, either the content or the response headers, or both, can be analyzed.</p> <p>Parameters:</p> Name Type Description Default <code>content</code> <code>list[bytes]</code> <p>downloaded content.</p> required <code>responses</code> <code>list[ClientResponse]</code> <p>responses to requests for resources.</p> required <p>Returns:</p> Name Type Description <code>list</code> <code>bool</code> <p>sequence of resource end indicators. The order of indicators corresponds to the         order of responses to requests in the batch that was passed to the function.</p> Source code in <code>src\\yass\\data_collectors\\api.py</code> <pre><code>def eor_signal(\n    self, content: list[bytes], responses: list[ClientResponse]\n) -&gt; list[bool]:\n    \"\"\"\n    Returns the resource end indicator for a batch of request results.\n    Depending on the triggers installed on the resource, either the content or the response headers,\n    or both, can be analyzed.\n\n    Args:\n        content (list[bytes]): downloaded content.\n        responses (list[ClientResponse]): responses to requests for resources.\n\n    Returns:\n        list (bool): sequence of resource end indicators. The order of indicators corresponds to the\n                    order of responses to requests in the batch that was passed to the function.\n    \"\"\"\n    signal_seq: list[list[bool]] = []\n    for searcher in self.content_searchers:\n        bits = [searcher.is_end_of_resource(cont) for cont in content]\n        signal_seq.append(bits)\n    for searcher in self.headers_searchers:\n        bits = [searcher.is_end_of_resource(resp) for resp in responses]\n        signal_seq.append(bits)\n    return self._resolve_bitmap(signal_seq)\n</code></pre>"},{"location":"api/api_resources/","title":"Implementations","text":""},{"location":"api/api_resources/#core-classes","title":"Core classes","text":""},{"location":"api/api_resources/#working-with-api","title":"Working with API","text":""},{"location":"api/api_resources/#yass.resources.ApiRequest","title":"<code>ApiRequest(name: str, endpoint: EndpointPath, io_context: IOContext, collect_interval: ActionCondition = AlwaysRun(), fix_params: MutableMapping[str, str] | Undefined = YassUndefined, mutable_params: MutableMapping[str, MutableSequence] | Undefined = YassUndefined, has_pages: bool = True)</code>","text":"<p>             Bases: <code>BaseResourceRequest</code></p> <p>API resource request class.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>request ID.</p> required <code>endpoint</code> <code>EndpointPath</code> <p>the API endpoint that will be processed by this request.</p> required <code>fix_params</code> <code>MutableMapping[str, str]</code> <p>HTTP request parameters that do not change from request to request.</p> <code>YassUndefined</code> <code>mutable_params</code> <code>MutableMapping[str, MutableSequence]</code> <p>HTTP request parameters that change from request to request.</p> <code>YassUndefined</code> <code>io_context</code> <code>IOContext</code> <p>I/O context instance. Specifies the actions that need to be performed with the data obtained as a                     result of the request execution (in what format to deserialize, where to save, whether the information needs to be further processed, and so on).</p> required <code>collect_interval</code> <code>ActionCondition</code> <p>request activity interval. See ActionCondition for details. Defaults to AlwaysRun().</p> <code>AlwaysRun()</code> <code>has_pages</code> <code>bool</code> <p>if True, then the class will try to crawl the resource with the request parameters specified in the next generated url, page by page. Defaults to True.</p> <code>True</code> Source code in <code>src\\yass\\resources\\api.py</code> <pre><code>def __init__(\n    self,\n    name: str,\n    endpoint: EndpointPath,\n    io_context: IOContext,\n    collect_interval: ActionCondition = AlwaysRun(),\n    fix_params: MutableMapping[str, str] | Undefined = YassUndefined,\n    mutable_params: MutableMapping[str, MutableSequence]\n    | Undefined = YassUndefined,\n    has_pages: bool = True,\n) -&gt; None:\n    super().__init__(name, io_context, collect_interval, has_pages)\n    self.endpoint: EndpointPath = endpoint\n    self.fix_params: MutableMapping[str, str] = fix_params\n    self.mutable_params: MutableMapping[str, MutableSequence] = (\n        mutable_params\n    )\n</code></pre>"},{"location":"api/api_resources/#yass.resources.ApiRequest.change_interval","title":"<code>change_interval(interval: ActionCondition) -&gt; None</code>","text":"<p>The method replaces the original activity interval with a new one.</p> <p>Parameters:</p> Name Type Description Default <code>interval</code> <code>ActionCondition</code> <p>a new instance of the activity control class.</p> required Source code in <code>src\\yass\\resources\\api.py</code> <pre><code>def change_interval(self, interval: ActionCondition) -&gt; None:\n    \"\"\"\n    The method replaces the original activity interval with a new one.\n\n    Args:\n        interval (ActionCondition): a new instance of the activity control class.\n    \"\"\"\n    self.collect_interval: ActionCondition = interval\n</code></pre>"},{"location":"api/api_resources/#yass.resources.ApiRequest.set_mutable_field","title":"<code>set_mutable_field(params: Iterable) -&gt; None</code>","text":"<p>Setter for http request fields with changeable values.</p> <p>Parameters:</p> Name Type Description Default <code>params</code> <code>dict | list | tuple</code> <p>either a dictionary with one key-value pair, or a tuple or list with two elements.</p> required Source code in <code>src\\yass\\resources\\api.py</code> <pre><code>def set_mutable_field(self, params: Iterable) -&gt; None:\n    \"\"\"\n    Setter for http request fields with changeable values.\n\n    Args:\n        params (dict|list|tuple): either a dictionary with one key-value pair, or a tuple or list with two elements.\n    \"\"\"\n    if isinstance(params, (list, tuple)):\n        self.mutable_params.__setitem__(*params)\n    else:\n        self.mutable_params.update(params)\n</code></pre>"},{"location":"api/api_resources/#yass.resources.ApiRequest.set_persist_field","title":"<code>set_persist_field(params: Iterable) -&gt; None</code>","text":"<p>Setter for http request fields with a constant value.</p> <p>Parameters:</p> Name Type Description Default <code>params</code> <code>dict | list | tuple</code> <p>either a dictionary with one key-value pair, or a tuple or list with two elements.</p> required Source code in <code>src\\yass\\resources\\api.py</code> <pre><code>def set_persist_field(self, params: Iterable) -&gt; None:\n    \"\"\"\n    Setter for http request fields with a constant value.\n\n    Args:\n        params (dict|list|tuple): either a dictionary with one key-value pair, or a tuple or list with two elements.\n    \"\"\"\n    if isinstance(params, (list, tuple)):\n        self.fix_params.__setitem__(*params)\n    else:\n        self.fix_params.update(params)\n</code></pre>"},{"location":"api/api_resources/#yass.resources.ApiResource","title":"<code>ApiResource(url: str, *, extra_headers: dict = {}, eor_triggers: list[ApiEORTrigger] | Undefined = YassUndefined, max_batch: int = 1, delay: int | float = 1, request_timeout: int | float = 5)</code>","text":"<p>             Bases: <code>BaseResource</code></p> <p>Class - access point to the API resource.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>api start url.</p> required <code>extra_headers</code> <code>dict</code> <p>additional headers. For example, these could be headers required for authorization in the API. Defaults to {}.</p> <code>{}</code> <code>eor_triggers</code> <code>list[ApiEORTrigger]</code> <p>a list of triggers for notifying about the end of a resource. Defaults to [_EMPTY_EOR_TRIGGER].</p> <code>YassUndefined</code> <code>max_batch</code> <code>int</code> <p>the maximum number of requests to a resource. Most often, you can use the rate limit value of the api service for this parameter. Defaults to 1.</p> <code>1</code> <code>delay</code> <code>int | float</code> <p>delay before sending the next batch of requests. Defaults to 1.</p> <code>1</code> <code>request_timeout</code> <code>int | float</code> <p>the maximum waiting time for a response to a request. Applies to every single http request. Defaults to 5.</p> <code>5</code> Source code in <code>src\\yass\\resources\\api.py</code> <pre><code>def __init__(\n    self,\n    url: str,\n    *,\n    extra_headers: dict = {},\n    eor_triggers: list[ApiEORTrigger] | Undefined = YassUndefined,\n    max_batch: int = 1,\n    delay: int | float = 1,\n    request_timeout: int | float = 5,\n):\n    super().__init__(url, delay=delay, request_timeout=request_timeout)\n    self.max_batch: int = max_batch\n    self.endpoints: dict[str, EndpointPath] = {}\n    self.batch = BatchCounter(self)\n    self.extra_headers: dict = extra_headers\n    self.eor_triggers: list[ApiEORTrigger] | Undefined = eor_triggers\n</code></pre>"},{"location":"api/api_resources/#yass.resources.ApiResource.configure","title":"<code>configure(*, extra_headers: dict | None = None, max_batch: int | None = None, delay: int | float | None = None, eor_triggers: list[ApiEORTrigger] | None = None) -&gt; Self</code>","text":"<p>The method replaces one or more class parameters and returns the updated class.</p> Source code in <code>src\\yass\\resources\\api.py</code> <pre><code>def configure(\n    self,\n    *,\n    extra_headers: dict | None = None,\n    max_batch: int | None = None,\n    delay: int | float | None = None,\n    eor_triggers: list[ApiEORTrigger] | None = None,\n) -&gt; Self:\n    \"\"\"\n    The method replaces one or more class parameters and returns the updated class.\n    \"\"\"\n    new_params = {\n        key: value\n        for key, value in locals().items()\n        if key != \"self\" and value is not None\n    }\n    self.batch.barrier = cast(int, max_batch)\n    default_params: dict[str, Any] = vars(self)\n    default_params.update(new_params)\n    for param, value in filter(\n        lambda x: hasattr(self, x[0]), default_params.items()\n    ):\n        setattr(self, param, value)\n    return self\n</code></pre>"},{"location":"api/api_resources/#service-classes-and-utilities","title":"Service classes and utilities","text":""},{"location":"api/api_resources/#yass.resources.BatchCounter","title":"<code>BatchCounter(resource: ApiResource)</code>","text":"<p>The class is a special data structure for API resources that helps implement throttling - limiting the load on a resource. With BatchCounter, the resource request limit is constantly redistributed between running data collectors in order not to overload the resource with requests. Operations to change the limit counter occur atomically.</p> <p>Parameters:</p> Name Type Description Default <code>resource</code> <code>ApiResource</code> <p>resource for which the limit counter will be created.</p> required Source code in <code>src\\yass\\resources\\api.py</code> <pre><code>def __init__(self, resource: ApiResource):\n    self.barrier: int = resource.max_batch\n    self._max_batch: int = resource.max_batch\n    self.active_tasks: int = 0\n    self.count_lock = Lock()\n    self.zero_control = Event()\n</code></pre>"},{"location":"api/api_resources/#yass.resources.BatchCounter.acquire_batch","title":"<code>acquire_batch() -&gt; int</code>  <code>async</code>","text":"<p>The method is used to capture part (in the case of several data collectors) or the entire limit (in the case of one running data collector) of requests. Control over the remainder of the limit is implemented on the principle of a semaphore - in the case of a zero balance, the data collector will not continue execution until another releases part of the limit. Each call to the method increases the active task counter by one.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>batch size.</p> Source code in <code>src\\yass\\resources\\api.py</code> <pre><code>async def acquire_batch(self) -&gt; int:\n    \"\"\"\n    The method is used to capture part (in the case of several data collectors) or the entire\n    limit (in the case of one running data collector) of requests.\n    Control over the remainder of the limit is implemented on the principle of a\n    semaphore - in the case of a zero balance, the data collector will not continue\n    execution until another releases part of the limit.\n    Each call to the method increases the active task counter by one.\n\n    Returns:\n        int: batch size.\n    \"\"\"\n    self.active_tasks += 1\n    print(\n        f\"\u041a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0430\u043a\u0442\u0438\u0432\u043d\u044b\u0445 \u0437\u0430\u0434\u0430\u0447 \u043d\u0430 \u0442\u0435\u043a\u0443\u0449\u0438\u0439 \u043c\u043e\u043c\u0435\u043d\u0442 {self.active_tasks}.\"\n    )\n    # async with self.count_lock:\n    async with self.count_lock:\n        print(\"\u041e\u0436\u0438\u0434\u0430\u044e \u043e\u0441\u0432\u043e\u0431\u043e\u0436\u0434\u0435\u043d\u0438\u044f \u0431\u043b\u043e\u043a\u0438\u0440\u043e\u0432\u043e\u043a.\")\n        if self.barrier &lt; min(self.min_batch):\n            await self.zero_control.wait()\n        print(\"\u0411\u043b\u043e\u043a\u0438\u0440\u043e\u0432\u043a\u0438 \u0437\u0430\u0445\u0432\u0430\u0447\u0435\u043d\u044b.\")\n        acquire_size: int = max(self.barrier, *self.min_batch)\n        print(f\"\u0417\u0430\u0445\u0432\u0430\u0447\u0435\u043d\u043d\u044b\u0439 \u043b\u0438\u043c\u0438\u0442 \u0441\u043e\u0441\u0442\u0430\u0432\u043b\u044f\u0435\u0442 {acquire_size}.\")\n        self.barrier = self.barrier - acquire_size\n        print(f\"\u0414\u043e\u0441\u0442\u0443\u043f\u043d\u044b\u0439 \u043b\u0438\u043c\u0438\u0442 \u0441\u043e\u0441\u0442\u0430\u0432\u043b\u044f\u0435\u0442 {self.barrier}.\")\n    self.zero_control.clear()\n    return acquire_size\n</code></pre>"},{"location":"api/api_resources/#yass.resources.BatchCounter.min_batch","title":"<code>min_batch: tuple[int, int]</code>  <code>property</code>","text":"<p>Minimum batch size range. Depends on the number of active data collectors. Cannot be less than one.</p> <p>Returns:</p> Name Type Description <code>tuple</code> <code>(int, int)</code> <p>boundaries of the norm of requests for one data collector.</p>"},{"location":"api/api_resources/#yass.resources.BatchCounter.recalc_limit","title":"<code>recalc_limit(current_size: int) -&gt; int</code>","text":"<p>The method is used to override the available request limit. If excess limits have been captured (for example, one data collector starts earlier than all the others and captures the entire available limit), they will be released for redistribution between all running data collectors. And vice versa, if it is possible to select the entire balance of the limit, it will be used.</p> <p>Parameters:</p> Name Type Description Default <code>current_size</code> <code>int</code> <p>current batch size.</p> required <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>updated available limit.</p> Source code in <code>src\\yass\\resources\\api.py</code> <pre><code>def recalc_limit(self, current_size: int) -&gt; int:\n    \"\"\"\n    The method is used to override the available request limit. If excess limits\n    have been captured (for example, one data collector starts earlier than all\n    the others and captures the entire available limit), they will be released for\n    redistribution between all running data collectors. And vice versa, if it is\n    possible to select the entire balance of the limit, it will be used.\n\n    Args:\n        current_size (int): current batch size.\n\n    Returns:\n        int: updated available limit.\n    \"\"\"\n    if not self.count_lock.locked() and self.barrier &gt;= 0:\n        new_batch: int = current_size + self.barrier\n        self.barrier = 0\n    else:\n        standart_batch: int = min(self.min_batch)\n        if (new_batch := current_size - standart_batch) &gt; 0:\n            print(\n                f\"\u041f\u0435\u0440\u0435\u0441\u0447\u0435\u0442 \u0440\u0430\u0437\u043c\u0435\u0440\u0430 \u0431\u0430\u0442\u0447\u0430. \u0422\u0435\u043a\u0443\u0449\u0438\u0439 \u0440\u0430\u0437\u043c\u0435\u0440 \u0441\u043e\u0441\u0442\u0430\u0432\u043b\u044f\u0435\u0442 {current_size}, \u0438\u0437\u0431\u044b\u0442\u043e\u043a \u0437\u0430\u0445\u0432\u0430\u0447\u0435\u043d\u043d\u044b\u0445 \u0431\u0430\u0442\u0447\u0435\u0439 \u0441\u043e\u0441\u0442\u0430\u0432\u043b\u044f\u0435\u0442 {standart_batch}.\"\n            )\n            self.barrier += standart_batch\n            self.zero_control.set()\n        else:\n            new_batch = current_size\n    return new_batch\n</code></pre>"},{"location":"api/api_resources/#yass.resources.BatchCounter.release_batch","title":"<code>release_batch(current_size: int) -&gt; None</code>","text":"<p>Using this method, part of the resource request limit is released.</p> <p>Parameters:</p> Name Type Description Default <code>current_size</code> <code>int</code> <p>current batch size.</p> required Source code in <code>src\\yass\\resources\\api.py</code> <pre><code>def release_batch(self, current_size: int) -&gt; None:\n    \"\"\"\n    Using this method, part of the resource request limit is released.\n\n    Args:\n        current_size (int): current batch size.\n    \"\"\"\n    self.barrier += current_size\n    print(\n        f\"\u0412\u044b\u0441\u0432\u043e\u0431\u043e\u0434\u0438\u043b\u0441\u044f \u043b\u0438\u043c\u0438\u0442 \u043d\u0430 {current_size} \u0437\u0430\u043f\u0440\u043e\u0441\u043e\u0432. \u0414\u043e\u0441\u0442\u0443\u043f\u043d\u044b\u0439 \u043b\u0438\u043c\u0438\u0442 \u0441\u043e\u0441\u0442\u0430\u0432\u043b\u044f\u0435\u0442 {self.barrier}.\"\n    )\n    self.active_tasks -= 1\n</code></pre>"},{"location":"api/api_resources/#yass.resources.ContentLengthEORTrigger","title":"<code>ContentLengthEORTrigger(min_content_length: int)</code>","text":"<p>             Bases: <code>ApiEORTrigger</code></p> <p>A trigger that terminates interaction with a resource based on the length of the content. Not only zero length, but also any other value can act as a control value.</p> <p>Parameters:</p> Name Type Description Default <code>min_content_length</code> <code>int</code> <p>Minimum content length in bytes. Used as a threshold - all values                     equal to or below min_content_length cause the trigger to fire.</p> required Source code in <code>src\\yass\\resources\\api.py</code> <pre><code>def __init__(self, min_content_length: int):\n    self.stop_value = min_content_length\n    self.search_type = \"headers\"\n</code></pre>"},{"location":"api/api_resources/#yass.resources.MaxPageEORTrigger","title":"<code>MaxPageEORTrigger(*, search_area: Literal['content', 'headers'], current_page_field: str, max_page_field: str)</code>","text":"<p>             Bases: <code>ApiEORTrigger</code></p> <p>A trigger that looks for the maximum page attribute in the content or headers. The current page attribute is also looked up for matching.</p> <p>Parameters:</p> Name Type Description Default <code>search_area</code> <code>Literal['content', 'headers']</code> <p>the place where attributes are searched.</p> required <code>current_page_field</code> <code>str</code> <p>attribute name with the value of the current page.</p> required <code>max_page_field</code> <code>str</code> <p>the name of the attribute with the maximum page value.</p> required Source code in <code>src\\yass\\resources\\api.py</code> <pre><code>def __init__(\n    self,\n    *,\n    search_area: Literal[\"content\", \"headers\"],\n    current_page_field: str,\n    max_page_field: str,\n):\n    self.fields: tuple[str, str] = (current_page_field, max_page_field)\n    self.search_area: str = search_area\n    self.content_handler: Callable = lambda x: x\n    self.search_type = search_area\n</code></pre>"},{"location":"api/api_resources/#yass.resources.StatusEORTrigger","title":"<code>StatusEORTrigger(status_code: int)</code>","text":"<p>             Bases: <code>ApiEORTrigger</code></p> <p>A trigger that signals the end of a resource based on the status of the response. For example, the API may continue to accept requests, but return a 204 response code. The specified code can act as a control value for this trigger.</p> <p>Parameters:</p> Name Type Description Default <code>status_code</code> <code>int</code> <p>response control code.</p> required Source code in <code>src\\yass\\resources\\api.py</code> <pre><code>def __init__(self, status_code: int):\n    self.stop_status = status_code\n    self.search_type = \"headers\"\n</code></pre>"},{"location":"api/base_data_collectors/","title":"Interfaces","text":""},{"location":"api/base_data_collectors/#core-classes","title":"Core classes","text":""},{"location":"api/base_data_collectors/#yass.data_collectors.BaseDataCollector","title":"<code>BaseDataCollector(resource: BaseResource, query: BaseResourceRequest)</code>","text":"<p>             Bases: <code>YassCore</code></p> <p>Base data collector class. Data collectors are objects that directly make a request to a resource, call the data handler pipeline, and send data to the store. Data collectors take into account the restrictions associated with the resource, such as the rate limit, the interval for processing the resource, and the data format received when accessing the resource. For each instance of a request to a resource, a data collector is created. At the moment, only work with API resources is available.</p> <p>Attributes:</p> Name Type Description <code>delay</code> <code>int | float</code> <p>delay before sending requests.</p> <code>timeout</code> <code>int | float</code> <p>waiting time for a response from the data source.</p> <code>collect_trigger</code> <code>ActionCondition</code> <p>a trigger, the firing of which allows you to begin processing the data source.</p> <code>eor_status</code> <code>bool</code> <p>the status of no payload in the data source.</p> <code>_write_channel</code> <code>ContentQueue</code> <p>a buffer in memory in which data is stored before uploading to the backend.</p> <code>url_series</code> <code>AsyncGenerator</code> <p>a link generator created by a Request instance.</p> <code>pipeline</code> <code>IOBoundPipeline</code> <p>an instance of the pipeline class associated with a request that is processed by the data collector.</p> <code>input_format</code> <code>str</code> <p>format of incoming data.</p> <code>output_format</code> <code>str</code> <p>the format in which the data should be saved.</p> <code>path_producer</code> <code>PathTemplate</code> <p>data path generator.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>ApiRequest</code> <p>an instance of the request to the resource for which the data collector is being created.</p> required <code>resource</code> <code>ApiResource</code> <p>a resource from which additional information is retrieved to initialize the data collector.</p> required Source code in <code>src\\yass\\data_collectors\\base.py</code> <pre><code>def __init__(self, resource: BaseResource, query: BaseResourceRequest):\n    \"\"\"\n    Args:\n        query (ApiRequest): an instance of the request to the resource for which the data collector is being created.\n        resource (ApiResource): a resource from which additional information is retrieved to initialize the data collector.\n    \"\"\"\n    self._name: str = query.name\n    self.delay: int | float = resource.delay\n    self.timeout: int | float = resource.request_timeout\n    self.collect_trigger: ActionCondition = query.collect_interval\n    io_context: IOContext = query.io_context\n    storage: BaseBufferableStorage = io_context.storage\n    self.eor_status = False\n    self._write_channel: ContentQueue = storage.create_buffer(query)\n    self.url_series: Callable[..., AsyncGenerator[str, None]] = (\n        query.gen_url\n    )\n    self.pipeline: IOBoundPipeline = io_context.pipeline\n    self.input_format: str = io_context.in_format\n    self.output_format: str = io_context.out_format\n    if io_context.path_temp:\n        self.path_producer: PathTemplate = io_context.path_temp\n    else:\n        self.path_producer = io_context.attache_pathgenerator()\n        self.path_producer.add_segment(\"\", 1, [urlparse(resource.url)[1]])\n        self.path_producer.add_segment(\"\", 2, [query.name])\n        self.path_producer.add_segment(\n            \"_\", 3, [date.today, query.name, time]\n        )\n        rpp(\n            f\"\u041f\u0440\u0438\u043c\u0435\u0440 \u0441\u0444\u043e\u0440\u043c\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u043e\u0433\u043e \u0434\u0435\u0444\u043e\u043b\u0442\u043d\u043e\u0433\u043e \u043f\u0443\u0442\u0438: {self.path_producer.render_path(self.output_format)}\"\n        )\n</code></pre>"},{"location":"api/base_data_collectors/#yass.data_collectors.BaseDataCollector.process_requests","title":"<code>process_requests(urls: list[str]) -&gt; list[bytes]</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>The method sends requests to the list of urls passed as a parameter. The method must return a batch of serialized content. It is also assumed that this method will also implement the necessary checks (for example, whether the resource has expired or not, whether all response codes suit us, etc.)</p> <p>Parameters:</p> Name Type Description Default <code>urls</code> <code>list[str]</code> <p>list of urls to process.</p> required <p>Returns:</p> Name Type Description <code>list</code> <code>bytes</code> <p>description</p> Source code in <code>src\\yass\\data_collectors\\base.py</code> <pre><code>@abstractmethod\nasync def process_requests(self, urls: list[str]) -&gt; list[bytes]:\n    \"\"\"\n    The method sends requests to the list of urls passed as a parameter. The method must return a batch\n    of serialized content. It is also assumed that this method will also implement the necessary checks\n    (for example, whether the resource has expired or not, whether all response codes suit us, etc.)\n\n    Args:\n        urls (list[str]): list of urls to process.\n\n    Returns:\n        list (bytes): _description_\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/base_data_collectors/#yass.data_collectors.BaseDataCollector.start","title":"<code>start() -&gt; Task</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Entry point for running the data collector. The method starts the procedure for crawling the resource according to the parameters of the request sent to the data collector. The method must return itself, wrapped in an asyncio task.</p> Source code in <code>src\\yass\\data_collectors\\base.py</code> <pre><code>@abstractmethod\nasync def start(self) -&gt; Task:\n    \"\"\"\n    Entry point for running the data collector. The method starts the procedure\n    for crawling the resource according to the parameters of the request sent to the data collector.\n    The method must return itself, wrapped in an asyncio task.\n    \"\"\"\n    await self.collect_trigger.pending()\n    await self._write_channel.storage.launch_session()\n    ...\n</code></pre>"},{"location":"api/base_data_collectors/#service-classes-and-utilities","title":"Service classes and utilities","text":""},{"location":"api/base_data_collectors/#yass.data_collectors.common.build_proxy_url","title":"<code>build_proxy_url(*, url_address: str = '', port: int | None = None, username: str = '', password: str = '', display_url: bool = False) -&gt; str</code>","text":"<p>Conventional method of registering a link to a proxy server. If necessary, it allows you to output the resulting link to standard output.</p> <p>Parameters:</p> Name Type Description Default <code>url_address</code> <code>str</code> <p>url address of the proxy server or service that provides the proxy.                     The exact form of this address depends on the provider providing the proxy server.</p> <code>''</code> <code>port</code> <code>int | None</code> <p>proxy server port. Defaults to None.</p> <code>None</code> <code>username</code> <code>str</code> <p>login for authorization in the proxy server.</p> <code>''</code> <code>password</code> <code>str</code> <p>password for authorization in the proxy server.</p> <code>''</code> <code>display_url</code> <code>bool</code> <p>print the resulting url to stdout. Defaults to False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>url string for accessing the proxy server.</p> Source code in <code>src\\yass\\data_collectors\\common.py</code> <pre><code>def build_proxy_url(\n    *,\n    url_address: str = \"\",\n    port: int | None = None,\n    username: str = \"\",\n    password: str = \"\",\n    display_url: bool = False,\n) -&gt; str:\n    \"\"\"\n    Conventional method of registering a link to a proxy server. If necessary,\n    it allows you to output the resulting link to standard output.\n\n    Args:\n        url_address (str, optional): url address of the proxy server or service that provides the proxy.\n                                The exact form of this address depends on the provider providing the proxy server.\n        port (int | None, optional): proxy server port. Defaults to None.\n        username (str, optional): login for authorization in the proxy server.\n        password (str, optional): password for authorization in the proxy server.\n        display_url (bool, optional): print the resulting url to stdout. Defaults to False.\n\n    Returns:\n        str: url string for accessing the proxy server.\n    \"\"\"\n    url_string: URL = (\n        URL(url_address)\n        .with_port(port)\n        .with_password(password)\n        .with_user(username)\n    )\n    _PROXY_LIST.append(url_string.human_repr())\n    if display_url:\n        print(f\"Prepared proxy url {url_string.human_repr()}\")\n    return url_string.human_repr()\n</code></pre>"},{"location":"api/base_data_collectors/#yass.data_collectors.common.get_proxy_list","title":"<code>get_proxy_list() -&gt; _ProxyList</code>","text":"<p>The function returns a copy of the current proxy list.</p> <p>Returns:</p> Name Type Description <code>_ProxyList</code> <code>_ProxyList</code> <p>a copy of the current proxy list.</p> Source code in <code>src\\yass\\data_collectors\\common.py</code> <pre><code>def get_proxy_list() -&gt; _ProxyList:\n    \"\"\"\n    The function returns a copy of the current proxy list.\n\n    Returns:\n        _ProxyList: a copy of the current proxy list.\n    \"\"\"\n    return deepcopy(_PROXY_LIST)\n</code></pre>"},{"location":"api/base_data_collectors/#yass.data_collectors.common.remove_proxy_url","title":"<code>remove_proxy_url(position: int) -&gt; None</code>","text":"<p>Removes a link to a proxy server by position in the list.</p> <p>Parameters:</p> Name Type Description Default <code>position</code> <code>int</code> <p>position of the link to the proxy server. Please note that the first link is at position number zero.</p> required Source code in <code>src\\yass\\data_collectors\\common.py</code> <pre><code>def remove_proxy_url(position: int) -&gt; None:\n    \"\"\"\n    Removes a link to a proxy server by position in the list.\n\n    Args:\n        position (int): position of the link to the proxy server. Please note that the first link is at position number zero.\n    \"\"\"\n    del _PROXY_LIST[position]\n</code></pre>"},{"location":"api/base_resources/","title":"Interfaces","text":""},{"location":"api/base_resources/#core-classes","title":"Core classes","text":""},{"location":"api/base_resources/#yass.resources.BaseResource","title":"<code>BaseResource(url: str, *, delay: int | float = 1, request_timeout: int | float = 5)</code>","text":"<p>             Bases: <code>YassCore</code></p> <p>Base class for resources. Essentially, the Resource class is an abstraction of the entry point for interacting with some real data source (in the case of Yass, a network resource like a site or api). The class accumulates information about restrictions on the use of a data source, including the permissible frequency of accessing it, all planned queries to the source, and other information that forms the context for working with the data source. At the moment, only the resource API implementation is available.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>url address of the resource. As a rule, this is a full-fledged link without dynamic parts of the URL address.</p> required <code>delay</code> <code>int | float</code> <p>delay before sending a request to a resource, in seconds. Defaults to 1.</p> <code>1</code> <code>request_timeout</code> <code>int | float</code> <p>timeout for requests to the resource. Defaults to 5.</p> <code>5</code> Source code in <code>src\\yass\\resources\\base.py</code> <pre><code>def __init__(\n    self,\n    url: str,\n    *,\n    delay: int | float = 1,\n    request_timeout: int | float = 5,\n):\n    self.url: str = url\n    self.delay: int | float = delay\n    self.request_timeout: int | float = request_timeout\n    self.queries: dict[str, BaseResourceRequest] = dict()\n</code></pre>"},{"location":"api/base_resources/#yass.resources.BaseResource.configure","title":"<code>configure(**kwargs) -&gt; Self</code>  <code>abstractmethod</code>","text":"<p>The method replaces one or more class parameters and returns the updated class.</p> Source code in <code>src\\yass\\resources\\base.py</code> <pre><code>@abstractmethod\ndef configure(self, **kwargs) -&gt; Self:\n    \"\"\"\n    The method replaces one or more class parameters and returns the updated class.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/base_resources/#yass.resources.BaseResource.delete_query","title":"<code>delete_query(name: str) -&gt; None</code>  <code>abstractmethod</code>","text":"<p>The method removes a request from those registered by identifier (name).</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>request name.</p> required <p>Raises:</p> Type Description <code>KeyError</code> <p>thrown if a request with the same name is not registered.</p> Source code in <code>src\\yass\\resources\\base.py</code> <pre><code>@abstractmethod\ndef delete_query(self, name: str) -&gt; None:\n    \"\"\"\n    The method removes a request from those registered by identifier (name).\n\n    Args:\n        name (str): request name.\n\n    Raises:\n        KeyError: thrown if a request with the same name is not registered.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/base_resources/#yass.resources.BaseResource.get_query","title":"<code>get_query(name: str) -&gt; BaseResourceRequest</code>  <code>abstractmethod</code>","text":"<p>The method returns the registered instance of the request object by its identifier (name).</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>request name.</p> required <p>Raises:</p> Type Description <code>KeyError</code> <p>thrown if a request with the same name is not registered.</p> <p>Returns:</p> Name Type Description <code>BaseResourceRequest</code> <code>BaseResourceRequest</code> <p>instance of the request object.</p> Source code in <code>src\\yass\\resources\\base.py</code> <pre><code>@abstractmethod\ndef get_query(self, name: str) -&gt; BaseResourceRequest:\n    \"\"\"\n    The method returns the registered instance of the request object by its identifier (name).\n\n    Args:\n        name (str): request name.\n\n    Raises:\n        KeyError: thrown if a request with the same name is not registered.\n\n    Returns:\n        BaseResourceRequest: instance of the request object.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/base_resources/#yass.resources.BaseResource.make_query","title":"<code>make_query(*args, **kwargs) -&gt; BaseResourceRequest</code>  <code>abstractmethod</code>","text":"<p>Factory method for creating request instances. The newly created object is registered in the instance attribute of the resource class. .</p> <p>Returns:</p> Name Type Description <code>BaseResourceRequest</code> <code>BaseResourceRequest</code> <p>instance of the request object.</p> Source code in <code>src\\yass\\resources\\base.py</code> <pre><code>@abstractmethod\ndef make_query(self, *args, **kwargs) -&gt; BaseResourceRequest:\n    \"\"\"\n    Factory method for creating request instances. The newly created object is\n    registered in the instance attribute of the resource class.\n    .\n\n    Returns:\n        BaseResourceRequest: instance of the request object.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/base_resources/#yass.resources.BaseResourceRequest","title":"<code>BaseResourceRequest(name: str, io_context: IOContext, collect_interval: ActionCondition = AlwaysRun(), has_pages: bool = True)</code>","text":"<p>             Bases: <code>YassCore</code></p> <p>Base class for resource request objects. The request object forms part of the resource processing context and generates URLs to which the resource will be processed (the implementation of this functionality depends on what type of resource the request is being prepared for). Each resource can have an unlimited number of requests - it all depends on how the resource is logically divided and which parts of it are required by the user.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>request name. Must be unique within a single resource.</p> required <code>io_context</code> <code>IOContext</code> <p>I/O context instance. Specifies the actions that need to be performed with the data obtained as a                     result of the request execution (in what format to deserialize, where to save, whether the information needs to be further processed, and so on).</p> required <code>collect_interval</code> <code>ActionCondition</code> <p>request activity interval. See ActionCondition for details. Defaults to AlwaysRun().</p> <code>AlwaysRun()</code> <code>has_pages</code> <code>bool</code> <p>if True, then links to crawl the resource will be generated taking into account the paginator. Defaults to True.</p> <code>True</code> Source code in <code>src\\yass\\resources\\base.py</code> <pre><code>def __init__(\n    self,\n    name: str,\n    io_context: IOContext,\n    collect_interval: ActionCondition = AlwaysRun(),\n    has_pages: bool = True,\n):\n    self.name: str = name\n    self.io_context: IOContext = io_context\n    self.collect_interval: ActionCondition = collect_interval\n    self.has_pages: bool = has_pages\n    self.enable = True\n</code></pre>"},{"location":"api/base_resources/#yass.resources.BaseResourceRequest.gen_url","title":"<code>gen_url() -&gt; AsyncGenerator[str, None]</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>The method creates a url generator to crawl the resource. The specific implementation of the method depends on the type of resource (there is a direct functional connection between the type of the request object and the type of the resource).</p> <p>Returns:</p> Name Type Description <code>AsyncGenerator</code> <code>(str, None)</code> <p>asynchronous link generator.</p> Source code in <code>src\\yass\\resources\\base.py</code> <pre><code>@abstractmethod\nasync def gen_url(self) -&gt; AsyncGenerator[str, None]:\n    \"\"\"\n    The method creates a url generator to crawl the resource. The specific implementation\n    of the method depends on the type of resource (there is a direct functional connection\n    between the type of the request object and the type of the resource).\n\n    Returns:\n        AsyncGenerator (str, None): asynchronous link generator.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/base_resources/#yass.resources.BaseResourceRequest.get_io_context","title":"<code>get_io_context() -&gt; IOContext</code>","text":"<p>The method returns the I/O context object assigned to the request instance.</p> <p>Returns:</p> Name Type Description <code>IOContext</code> <code>IOContext</code> <p>instance of I/O context.</p> Source code in <code>src\\yass\\resources\\base.py</code> <pre><code>def get_io_context(self) -&gt; IOContext:\n    \"\"\"\n    The method returns the I/O context object assigned to the request instance.\n\n    Returns:\n        IOContext: instance of I/O context.\n    \"\"\"\n    return self.io_context\n</code></pre>"},{"location":"api/base_resources/#service-classes-and-utilities","title":"Service classes and utilities","text":""},{"location":"api/base_resources/#yass.resources.ApiEORTrigger","title":"<code>ApiEORTrigger()</code>","text":"<p>             Bases: <code>YassCore</code></p> <p>The base class of triggers for API resources. Triggers are used as an indicator of the end of the payload in a resource based on a given criterion. This sign can be either the value of the response header or some value contained in the content.</p> Source code in <code>src\\yass\\resources\\base.py</code> <pre><code>def __init__(self):\n    self.search_type: Literal[\"content\", \"headers\"]\n</code></pre>"},{"location":"api/base_resources/#yass.resources.ApiEORTrigger.is_end_of_resource","title":"<code>is_end_of_resource(response: ClientResponse | bytes) -&gt; bool</code>  <code>abstractmethod</code>","text":"<p>The method returns True if the payload in the resource has ended. The implementation of a method depends on the validation rule inherent in the corresponding concrete class. Can accept a request response as either serialized content or an instance of the request response object.</p> <p>Parameters:</p> Name Type Description Default <code>response</code> <code>ClientResponse | bytes</code> <p>content or request object.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>returns True if the payload in the resource has ended.</p> Source code in <code>src\\yass\\resources\\base.py</code> <pre><code>@abstractmethod\ndef is_end_of_resource(self, response: ClientResponse | bytes) -&gt; bool:\n    \"\"\"\n    The method returns True if the payload in the resource has ended. The implementation of a\n    method depends on the validation rule inherent in the corresponding concrete class. Can\n    accept a request response as either serialized content or an instance of the request response\n    object.\n\n    Args:\n        response (ClientResponse | bytes): content or request object.\n\n    Returns:\n        bool: returns True if the payload in the resource has ended.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/base_scheduling/","title":"Interfaces","text":""},{"location":"api/base_scheduling/#core-classes","title":"Core classes","text":""},{"location":"api/base_scheduling/#yass.scheduling.base.ActionCondition","title":"<code>ActionCondition</code>","text":"<p>             Bases: <code>YassCore</code></p> <p>The base class for all subclasses that control the frequency of data collection. Subclasses of the ActionCondition class define a control event that causes requests to be sent to a physical resource by data collectors. Currently only scheduling based on calendar events and time is supported.</p>"},{"location":"api/base_scheduling/#yass.scheduling.base.ActionCondition.is_able","title":"<code>is_able() -&gt; bool</code>  <code>abstractmethod</code>","text":"<p>This method implements the control event verification logic.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>returns True if the control event occurred.</p> Source code in <code>src\\yass\\scheduling\\base.py</code> <pre><code>@abstractmethod\ndef is_able(self) -&gt; bool:\n    \"\"\"\n    This method implements the control event verification logic.\n\n    Returns:\n        bool: returns True if the control event occurred.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/base_scheduling/#yass.scheduling.base.ActionCondition.pending","title":"<code>pending() -&gt; None</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>The method starts waiting for the occurrence of a control event, checking it in an infinite loop until the condition becomes true.</p> Source code in <code>src\\yass\\scheduling\\base.py</code> <pre><code>@abstractmethod\nasync def pending(self) -&gt; None:\n    \"\"\"\n    The method starts waiting for the occurrence of a control event, checking it in an infinite loop until the condition becomes true.\n    \"\"\"\n    while not self.is_able():\n        ...\n</code></pre>"},{"location":"api/base_scheduling/#yass.scheduling.base.BaseLimit","title":"<code>BaseLimit</code>","text":"<p>             Bases: <code>YassCore</code></p> <p>Limit classes are a special type of scheduler intended exclusively for use in storage classes. Limits analyze the specified storage indicators and signal when a specified threshold is exceeded (for example, the amount of memory occupied, the number of elements, etc.). In storage they are used to dump data from the buffer to the backend.</p>"},{"location":"api/base_scheduling/#yass.scheduling.base.BaseLimit.is_overflowed","title":"<code>is_overflowed() -&gt; bool</code>  <code>abstractmethod</code>","text":"<p>The method implements specific logic for checking storage performance.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>returns True if the threshold has been passed.</p> Source code in <code>src\\yass\\scheduling\\base.py</code> <pre><code>@abstractmethod\ndef is_overflowed(self) -&gt; bool:\n    \"\"\"\n    The method implements specific logic for checking storage performance.\n\n    Returns:\n        bool: returns True if the threshold has been passed.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/base_storages/","title":"Interfaces","text":""},{"location":"api/base_storages/#core-classes","title":"Core classes","text":""},{"location":"api/base_storages/#yass.storages.base.BaseBufferableStorage","title":"<code>BaseBufferableStorage(engine: Undefined | Any = YassUndefined, *, handshake_timeout: int = 10, bufferize: bool = False, limit_type: Literal['none', 'memory', 'count', 'time'] = 'none', limit_capacity: int | float = 10)</code>","text":"<p>             Bases: <code>YassCore</code></p> <p>The base class for all other classes implementing data saving operations and interaction with the storage backend. Storage classes are used as a portal to the backend itself. Anything can act as a backend - a message broker, network storage, any database, if the type of downloaded data allows storage in such a backend. The purpose of storage classes is to optimize I/O by buffering data, providing load control on the end storage system, and recording statistics about how resources and data are used.</p> Source code in <code>src\\yass\\storages\\base.py</code> <pre><code>def __init__(\n    self,\n    engine: Undefined | Any = YassUndefined,\n    *,\n    handshake_timeout: int = 10,\n    bufferize: bool = False,\n    limit_type: Literal[\"none\", \"memory\", \"count\", \"time\"] = \"none\",\n    limit_capacity: int | float = 10,\n):\n    self.engine: Any = engine\n    self.connect_timeout: int = handshake_timeout\n    self.last_commit: datetime = datetime.now()\n    if bufferize and limit_type != \"none\":\n        self.limit: BaseLimit = setup_limit(\n            limit_type, limit_capacity, self\n        )\n    else:\n        self.limit: BaseLimit = UnableBufferize()\n    self.mem_buffer: BufferDispatcher = BufferDispatcher()\n    self.mem_alloc: Mb = 0\n    self.total_objects: int = 0\n    self._queue_lock: Lock = Lock()\n    self._timemark_lock: Lock = Lock()\n    self.active_session: bool = False\n</code></pre>"},{"location":"api/base_storages/#yass.storages.base.BaseBufferableStorage.check_limit","title":"<code>check_limit() -&gt; bool</code>","text":"<p>The method checks compliance with the limits set for data storage. More detailed information about limits can be found in the limits.py file.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>returns True if data storage limits have reached or exceeded the control parameter limit.</p> Source code in <code>src\\yass\\storages\\base.py</code> <pre><code>def check_limit(self) -&gt; bool:\n    \"\"\"\n    The method checks compliance with the limits set for data storage.\n    More detailed information about limits can be found in the limits.py file.\n\n    Returns:\n        bool: returns True if data storage limits have reached or exceeded the control parameter limit.\n    \"\"\"\n    return self.limit.is_overflowed()\n</code></pre>"},{"location":"api/base_storages/#yass.storages.base.BaseBufferableStorage.configure","title":"<code>configure(*, engine_proto: str | None = None, engine_params: dict | None = None, handshake_timeout: int | None = None, bufferize: bool | None = None, limit_type: Literal['none', 'memory', 'count', 'time'] | None = None, limit_capacity: int | float | None = None) -&gt; Self</code>","text":"<p>The method allows you to reconfigure all or individual backend parameters after creating an instance of the class. Accepts the same parameters as the class itself upon initialization.</p> Source code in <code>src\\yass\\storages\\base.py</code> <pre><code>def configure(\n    self,\n    *,\n    engine_proto: str | None = None,\n    engine_params: dict | None = None,\n    handshake_timeout: int | None = None,\n    bufferize: bool | None = None,\n    limit_type: Literal[\"none\", \"memory\", \"count\", \"time\"] | None = None,\n    limit_capacity: int | float | None = None,\n) -&gt; Self:\n    \"\"\"\n    The method allows you to reconfigure all or individual backend parameters after creating an instance of the class.\n    Accepts the same parameters as the class itself upon initialization.\n    \"\"\"\n    new_params = {\n        key: value\n        for key, value in locals().items()\n        if key != \"self\" and value is not None\n    }\n    engine_maker = _get_engine_factory(self.__class__)\n    self.engine = engine_maker(engine_proto, engine_kwargs=engine_params)\n    if bufferize and (limit_type and limit_type != \"none\"):\n        self.limit = setup_limit(limit_type, limit_capacity, self)\n    default_params = vars(self)\n    default_params.update(new_params)\n    for param, value in filter(\n        lambda x: hasattr(self, x[0]), default_params.items()\n    ):\n        setattr(self, param, value)\n    return self\n</code></pre>"},{"location":"api/base_storages/#yass.storages.base.BaseBufferableStorage.create_buffer","title":"<code>create_buffer(anchor: BaseResourceRequest) -&gt; ContentQueue</code>","text":"<p>The method registers a new in-memory buffer in the manager.</p> <p>Parameters:</p> Name Type Description Default <code>anchor</code> <code>BaseResourceRequest</code> <p>the object with which the buffer will be associated.</p> required <p>Returns:</p> Name Type Description <code>ContentQueue</code> <code>ContentQueue</code> <p>an instance of the in-memory buffer class.</p> Source code in <code>src\\yass\\storages\\base.py</code> <pre><code>def create_buffer(self, anchor: BaseResourceRequest) -&gt; ContentQueue:\n    \"\"\"\n    The method registers a new in-memory buffer in the manager.\n\n    Args:\n        anchor (BaseResourceRequest): the object with which the buffer will be associated.\n\n    Returns:\n        ContentQueue: an instance of the in-memory buffer class.\n    \"\"\"\n    return self.mem_buffer.make_channel(self, anchor)\n</code></pre>"},{"location":"api/base_storages/#yass.storages.base.BaseBufferableStorage.get_all_content","title":"<code>get_all_content() -&gt; list[AnyDataobj]</code>  <code>async</code>","text":"<p>The method returns all the content (without the paths where it should be stored) that is stored in buffers. During content retrieval, access to the buffer queue is blocked. Buffers are not cleared in this case.</p> Source code in <code>src\\yass\\storages\\base.py</code> <pre><code>async def get_all_content(self) -&gt; list[AnyDataobj]:\n    \"\"\"\n    The method returns all the content (without the paths where it should be stored) that\n    is stored in buffers. During content retrieval, access to the buffer queue is blocked.\n    Buffers are not cleared in this case.\n    \"\"\"\n    async with self._queue_lock:\n        return list(\n            chain(\n                *[\n                    buf.get_all_content()\n                    for buf in self.mem_buffer.get_buffers()\n                ]\n            )\n        )\n</code></pre>"},{"location":"api/base_storages/#yass.storages.base.BaseBufferableStorage.get_content","title":"<code>get_content(path: str) -&gt; AnyDataobj | None</code>  <code>async</code>","text":"<p>Returns the content that is stored at the given path. The search is carried out among all buffers registered in the buffer dispatcher.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>the path string where the content is stored.</p> required <p>Returns:</p> Name Type Description <code>AnyDataobj</code> <code>optional</code> <p>any data object that is captured in a buffers. If the object is not stored                 in the given path (for example, the queue was cleared after uploading to the                 backend), then None is returned.</p> Source code in <code>src\\yass\\storages\\base.py</code> <pre><code>async def get_content(self, path: str) -&gt; AnyDataobj | None:\n    \"\"\"\n    Returns the content that is stored at the given path.\n    The search is carried out among all buffers registered in the buffer dispatcher.\n\n    Args:\n        path (str): the path string where the content is stored.\n\n    Returns:\n        AnyDataobj (optional): any data object that is captured in a buffers. If the object is not stored\n                            in the given path (for example, the queue was cleared after uploading to the\n                            backend), then None is returned.\n    \"\"\"\n    async with self._queue_lock:\n        return self.mem_buffer.get_content(path)\n</code></pre>"},{"location":"api/base_storages/#yass.storages.base.BaseBufferableStorage.launch_session","title":"<code>launch_session() -&gt; None</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>The method is used to establish a session with the destination store. Implementation details depend on the type of backend used.</p> Source code in <code>src\\yass\\storages\\base.py</code> <pre><code>@abstractmethod\nasync def launch_session(self) -&gt; None:\n    \"\"\"\n    The method is used to establish a session with the destination store.\n    Implementation details depend on the type of backend used.\n\n    \"\"\"\n</code></pre>"},{"location":"api/base_storages/#yass.storages.base.BaseBufferableStorage.merge_to_backend","title":"<code>merge_to_backend(buf: ContentQueue) -&gt; None</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>The method transfers data directly to the backend (for storage or further distribution depending on the engine used) and clears in-memory buffers if the data is buffered.</p> Source code in <code>src\\yass\\storages\\base.py</code> <pre><code>@abstractmethod\nasync def merge_to_backend(self, buf: ContentQueue) -&gt; None:\n    \"\"\"\n    The method transfers data directly to the backend (for storage or further distribution depending on the engine used)\n    and clears in-memory buffers if the data is buffered.\n    \"\"\"\n    async with self._queue_lock:\n        ...\n</code></pre>"},{"location":"api/base_storages/#yass.storages.base.BaseBufferableStorage.registred_types","title":"<code>registred_types: Iterable[str]</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>The property provides a list of all available implementations of engines of a certain backend class.</p> <p>Returns:</p> Name Type Description <code>Iterable</code> <code>str</code> <p>list of available engines.</p>"},{"location":"api/base_storages/#yass.storages.base.BaseBufferableStorage.write","title":"<code>write(queue_id: Any, content: Iterable) -&gt; None</code>  <code>async</code>","text":"<p>Starts the content processing cycle in competitive mode and stores it in an intermediate buffer.</p> <p>Parameters:</p> Name Type Description Default <code>content</code> <code>list[bytes]</code> <p>any iterable object containing a series of serialized (not transformed) data.</p> required Source code in <code>src\\yass\\storages\\base.py</code> <pre><code>async def write(self, queue_id: Any, content: Iterable) -&gt; None:\n    \"\"\"\n    Starts the content processing cycle in competitive mode and stores it in an intermediate buffer.\n\n    Args:\n        content (list[bytes]): any iterable object containing a series of serialized (not transformed) data.\n    \"\"\"\n    buffer: ContentQueue = self.create_buffer(queue_id)\n    await buffer.parse_content(content)\n</code></pre>"},{"location":"api/base_storages/#service-classes-and-utilities","title":"Service classes and utilities","text":""},{"location":"api/base_storages/#yass.storages.base.BufferDispatcher","title":"<code>BufferDispatcher()</code>","text":"<p>This class accumulates information about the in-memory buffers used by the backend, and also provides a method for creating such buffers.</p> Source code in <code>src\\yass\\storages\\base.py</code> <pre><code>def __init__(self):\n    \"\"\"\n    This class accumulates information about the in-memory buffers used by the backend, and also provides a method for creating such buffers.\n    \"\"\"\n    self.queue_sequence: dict[BaseResourceRequest, ContentQueue] = dict()\n    self._lock: ThreadLock = ThreadLock()\n    self._cache: WeakValueDictionary[BaseResourceRequest, ContentQueue] = (\n        WeakValueDictionary()\n    )\n</code></pre>"},{"location":"api/base_storages/#yass.storages.base.BufferDispatcher.__iter__","title":"<code>__iter__() -&gt; Generator[ContentQueue, Any, None]</code>","text":"<p>The method wraps an array of buffers into a generator for iteration.</p> Source code in <code>src\\yass\\storages\\base.py</code> <pre><code>def __iter__(self) -&gt; Generator[ContentQueue, Any, None]:\n    \"\"\"\n    The method wraps an array of buffers into a generator for iteration.\n    \"\"\"\n    yield from self.get_buffers()\n</code></pre>"},{"location":"api/base_storages/#yass.storages.base.BufferDispatcher.get_buffers","title":"<code>get_buffers() -&gt; list[ContentQueue]</code>","text":"<p>The method returns an array of registered buffers.</p> <p>Returns:</p> Type Description <code>list[ContentQueue]</code> <p>list[ContentQueue]: an array of committed buffers.</p> Source code in <code>src\\yass\\storages\\base.py</code> <pre><code>def get_buffers(self) -&gt; list[ContentQueue]:\n    \"\"\"\n    The method returns an array of registered buffers.\n\n    Returns:\n        list[ContentQueue]: an array of committed buffers.\n    \"\"\"\n    return list(self.queue_sequence.values())\n</code></pre>"},{"location":"api/base_storages/#yass.storages.base.BufferDispatcher.get_content","title":"<code>get_content(path: str) -&gt; AnyDataobj | None</code>","text":"<p>Returns the content that is stored at the given path. The search is carried out among all buffers registered in the dispatcher.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>the path string where the content is stored.</p> required <p>Returns:</p> Name Type Description <code>AnyDataobj</code> <code>optional</code> <p>any data object that is captured in a buffers. If the object is not stored                 in the given path (for example, the queue was cleared after uploading to the                 backend), then None is returned.</p> Source code in <code>src\\yass\\storages\\base.py</code> <pre><code>def get_content(self, path: str) -&gt; AnyDataobj | None:\n    \"\"\"\n    Returns the content that is stored at the given path.\n    The search is carried out among all buffers registered in the dispatcher.\n\n    Args:\n        path (str): the path string where the content is stored.\n\n    Returns:\n        AnyDataobj (optional): any data object that is captured in a buffers. If the object is not stored\n                            in the given path (for example, the queue was cleared after uploading to the\n                            backend), then None is returned.\n    \"\"\"\n    for dataobj in filter(\n        lambda x: x.get_content(path), self.queue_sequence.values()\n    ):\n        return dataobj\n</code></pre>"},{"location":"api/base_storages/#yass.storages.base.BufferDispatcher.get_items","title":"<code>get_items() -&gt; tuple[tuple[BaseResourceRequest, ContentQueue], ...]</code>","text":"<p>The method returns a dictionary view of the current set of registered buffers.</p> <p>Returns:</p> Type Description <code>tuple[tuple[BaseResourceRequest, ContentQueue], ...]</code> <p>dict_items[BaseResourceRequest, ContentQueue]: I view in the form of \u201crequest - buffer\u201d pairs.</p> Source code in <code>src\\yass\\storages\\base.py</code> <pre><code>def get_items(\n    self,\n) -&gt; tuple[tuple[BaseResourceRequest, ContentQueue], ...]:\n    \"\"\"\n    The method returns a dictionary view of the current set of registered buffers.\n\n    Returns:\n        dict_items[BaseResourceRequest, ContentQueue]: I view in the form of \u201crequest - buffer\u201d pairs.\n    \"\"\"\n    return tuple(self.queue_sequence.items())\n</code></pre>"},{"location":"api/base_storages/#yass.storages.base.BufferDispatcher.make_channel","title":"<code>make_channel(storage: BaseBufferableStorage, id: BaseResourceRequest) -&gt; ContentQueue</code>","text":"<p>The method creates a buffer in memory and binds it to the specified request.</p> <p>Parameters:</p> Name Type Description Default <code>storage</code> <code>BaseBufferableStorage</code> <p>an instance of the backend class to which the buffer is bound.</p> required <code>id</code> <code>BaseResourceRequest</code> <p>an instance of the resource request class. Used to identify the format of input and output data                     and assigning a buffer to a specific request.</p> required <p>Returns:</p> Name Type Description <code>ContentQueue</code> <code>ContentQueue</code> <p>in-memory buffer instance.</p> Source code in <code>src\\yass\\storages\\base.py</code> <pre><code>def make_channel(\n    self, storage: BaseBufferableStorage, id: BaseResourceRequest\n) -&gt; ContentQueue:\n    \"\"\"\n    The method creates a buffer in memory and binds it to the specified request.\n\n    Args:\n        storage (BaseBufferableStorage): an instance of the backend class to which the buffer is bound.\n        id (BaseResourceRequest): an instance of the resource request class. Used to identify the format of input and output data\n                                and assigning a buffer to a specific request.\n\n    Returns:\n        ContentQueue: in-memory buffer instance.\n    \"\"\"\n    if id not in self._cache:\n        io_ctx: IOContext = id.io_context\n        queue = ContentQueue(storage, io_ctx.in_format, io_ctx.out_format)\n        with self._lock:\n            self._cache[id] = queue\n            self.queue_sequence[id] = queue\n    else:\n        queue: ContentQueue = self._cache[id]\n    print(\n        f\"\u0421\u043e\u0437\u0434\u0430\u043d\u043d\u044b\u0435 \u0432 \u043f\u0430\u043c\u044f\u0442\u0438 \u0431\u0443\u0444\u0435\u0440\u044b: {self.queue_sequence.keys(), self.queue_sequence.values()}\"\n    )\n    return queue\n</code></pre>"},{"location":"api/base_storages/#yass.storages.base.ContentQueue","title":"<code>ContentQueue(storage: BaseBufferableStorage, in_format: str, out_format: str)</code>","text":"<p>This class buffers content in memory, namely by placing it in a dictionary. Its main purpose is to avoid repeated I/O, which can significantly affect performance. The class also provides additional information about the stored content (size of memory allocated by objects, their number). The class also allows you to check whether a data object is in a queue and to loop through the path-data object pairs stored in the queue. In-memory buffers are used by data collectors to temporarily store downloaded content.</p> <p>Parameters:</p> Name Type Description Default <code>storage</code> <code>BaseBufferableStorage</code> <p>backend for which the queue is created.</p> required <code>in_format</code> <code>str</code> <p>input data format.</p> required <code>out_format</code> <code>str</code> <p>data upload format.</p> required Source code in <code>src\\yass\\storages\\base.py</code> <pre><code>def __init__(\n    self, storage: BaseBufferableStorage, in_format: str, out_format: str\n):\n    self.queue: dict[str, AnyDataobj] = dict()\n    self.storage: BaseBufferableStorage = storage\n    self.in_format: str = in_format\n    self.out_format: str = out_format\n    self.internal_lock = Lock()\n</code></pre>"},{"location":"api/base_storages/#yass.storages.base.ContentQueue.__iter__","title":"<code>__iter__() -&gt; Generator[tuple[str, Any], Any, None]</code>","text":"<p>When iterating, the method returns a pair of path and data object.</p> <p>Yields:</p> Type Description <code>str</code> <p>Generator[tuple[str, Any], Any, None]: generator that returns the target path and data.</p> Source code in <code>src\\yass\\storages\\base.py</code> <pre><code>def __iter__(self) -&gt; Generator[tuple[str, Any], Any, None]:\n    \"\"\"\n    When iterating, the method returns a pair of path and data object.\n\n    Yields:\n        Generator[tuple[str, Any], Any, None]: generator that returns the target path and data.\n    \"\"\"\n    yield from self.queue.items()\n</code></pre>"},{"location":"api/base_storages/#yass.storages.base.ContentQueue.block_state","title":"<code>block_state() -&gt; AsyncGenerator[Self, Any]</code>  <code>async</code>","text":"<p>The method locks the state of the buffer while working with it. The lock that is called is asynchronous.</p> Source code in <code>src\\yass\\storages\\base.py</code> <pre><code>@asynccontextmanager\nasync def block_state(self) -&gt; AsyncGenerator[Self, Any]:\n    \"\"\"\n    The method locks the state of the buffer while working with it. The lock that is called is asynchronous.\n    \"\"\"\n    try:\n        await self.internal_lock.acquire()\n        yield self\n    except Exception as exc:\n        raise exc\n    finally:\n        if self.internal_lock.locked():\n            self.internal_lock.release()\n</code></pre>"},{"location":"api/base_storages/#yass.storages.base.ContentQueue.get_all_content","title":"<code>get_all_content() -&gt; chain[AnyDataobj]</code>","text":"<p>The method wraps the content queue in a generator that produces values in the order in which the content was committed to the queue.</p> <p>Returns:</p> Type Description <code>chain[AnyDataobj]</code> <p>chain[AnyDataobj]: all data objects (without paths) currently present in the buffer, wrapped in a generator.</p> Source code in <code>src\\yass\\storages\\base.py</code> <pre><code>def get_all_content(self) -&gt; chain[AnyDataobj]:\n    \"\"\"\n    The method wraps the content queue in a generator that produces values in the order in which the content was committed to the queue.\n\n    Returns:\n        chain[AnyDataobj]: all data objects (without paths) currently present in the buffer, wrapped in a generator.\n    \"\"\"\n    return chain(self.queue.values())\n</code></pre>"},{"location":"api/base_storages/#yass.storages.base.ContentQueue.get_content","title":"<code>get_content(path: str) -&gt; AnyDataobj | None</code>","text":"<p>Returns the content that is stored at the given path.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>the path string where the content is stored.</p> required <p>Returns:</p> Name Type Description <code>AnyDataobj</code> <code>optional</code> <p>any data object that is captured in a buffer. If the object is not stored                 in the given path (for example, the queue was cleared after uploading to the                 backend), then None is returned.</p> Source code in <code>src\\yass\\storages\\base.py</code> <pre><code>def get_content(self, path: str) -&gt; AnyDataobj | None:\n    \"\"\"\n    Returns the content that is stored at the given path.\n\n    Args:\n        path (str): the path string where the content is stored.\n\n    Returns:\n        AnyDataobj (optional): any data object that is captured in a buffer. If the object is not stored\n                            in the given path (for example, the queue was cleared after uploading to the\n                            backend), then None is returned.\n    \"\"\"\n    return self.queue.get(path, None)\n</code></pre>"},{"location":"api/base_storages/#yass.storages.base.ContentQueue.memory_size","title":"<code>memory_size: int | float</code>  <code>property</code>","text":"<p>The property returns the amount of allocated memory in megabytes.</p> <p>Returns:</p> Type Description <code>int | float</code> <p>int | float: memory occupied by data in megabytes.</p>"},{"location":"api/base_storages/#yass.storages.base.ContentQueue.parse_content","title":"<code>parse_content(content: Iterable) -&gt; None</code>  <code>async</code>","text":"<p>The method parses the container with content on the path and the directly loaded content and distributes it in a queue. Based on the results of content distribution, it updates the time of the last data fixation in the backend and the statistics of downloaded data.</p> <p>Parameters:</p> Name Type Description Default <code>content</code> <code>Iterable</code> <p>a container with a path string where the content should be stored in the future, and data.</p> required Source code in <code>src\\yass\\storages\\base.py</code> <pre><code>async def parse_content(self, content: Iterable) -&gt; None:\n    \"\"\"\n    The method parses the container with content on the path and the directly loaded\n    content and distributes it in a queue. Based on the results of content distribution,\n    it updates the time of the last data fixation in the backend and the statistics\n    of downloaded data.\n\n    Args:\n        content (Iterable): a container with a path string where the content should be stored in the future, and data.\n    \"\"\"\n    for path, dataobj in content:\n        self.queue[path] = dataobj\n    rpp(f\"\u041a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043e\u0431\u044a\u0435\u043a\u0442\u043e\u0432 \u0432 \u0431\u0443\u0444\u0435\u0440\u0435 {len(self.queue)}\")\n    await self.storage._recalc_counters()\n    async with self.storage._timemark_lock:\n        self.storage.last_commit = datetime.now()\n        rpp(f\"\u041f\u043e\u0441\u043b\u0435\u0434\u043d\u0438\u0439 \u043a\u043e\u043c\u043c\u0438\u0442 \u0441\u043e\u0432\u0435\u0440\u0448\u0435\u043d \u0432 {self.storage.last_commit}\")\n    if self.storage.check_limit():\n        create_task(self.storage.merge_to_backend(self))\n</code></pre>"},{"location":"api/base_storages/#yass.storages.base.ContentQueue.reset","title":"<code>reset() -&gt; None</code>","text":"<p>The method clears the queue of all objects. As a rule, it is used at the end of the process of uploading data to the backend.</p> Source code in <code>src\\yass\\storages\\base.py</code> <pre><code>def reset(self) -&gt; None:\n    \"\"\"\n    The method clears the queue of all objects. As a rule,\n    it is used at the end of the process of uploading data to the backend.\n    \"\"\"\n    self.queue.clear()\n</code></pre>"},{"location":"api/base_storages/#yass.storages.base.ContentQueue.size","title":"<code>size: int</code>  <code>property</code>","text":"<p>The property returns the length of the queue or, in other words, the number of objects in it.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>number of objects in the queue.</p>"},{"location":"api/base_storages/#yass.storages.base.engine_factory","title":"<code>engine_factory(*_cls: type)</code>","text":"<p>The function registers factories for backend engines. The backend can be file storage, object storage, databases, buses and message brokers. Each backend has its own factory class, which can either generalize a group of backends or correspond to only one backend.</p> <p>Parameters:</p> Name Type Description Default <code>_cls</code> <code>type</code> <p>a sequence of classes to which the engine factory is assigned.</p> <code>()</code> Source code in <code>src\\yass\\storages\\base.py</code> <pre><code>def engine_factory(*_cls: type):\n    \"\"\"\n    The function registers factories for backend engines. The backend can be file storage,\n    object storage, databases, buses and message brokers. Each backend has its own factory class,\n    which can either generalize a group of backends or correspond to only one backend.\n\n    Args:\n        _cls (type): a sequence of classes to which the engine factory is assigned.\n    \"\"\"\n\n    def wrapped_func(func: Callable):\n        _ENGINE_FACTORIES[_cls] = func\n        return func\n\n    return wrapped_func\n</code></pre>"},{"location":"api/base_storages/#yass.storages.base.supported_engine_factories","title":"<code>supported_engine_factories()</code>","text":"<p>The function returns the currently available engine factories.</p> Source code in <code>src\\yass\\storages\\base.py</code> <pre><code>def supported_engine_factories():\n    \"\"\"\n    The function returns the currently available engine factories.\n    \"\"\"\n    return _ENGINE_FACTORIES\n</code></pre>"},{"location":"api/base_storages/#yass.storages.base.AnyDataobj","title":"<code>AnyDataobj = Any</code>  <code>module-attribute</code>","text":"<p>Alias for Any. Indicates that the object accepts any valid data object.</p>"},{"location":"api/blob_storage/","title":"Implementations","text":""},{"location":"api/blob_storage/#core-classes","title":"Core classes","text":""},{"location":"api/blob_storage/#yass.storages.blob.FsBlobStorage","title":"<code>FsBlobStorage(engine: Undefined | _FSSpecEngine = YassUndefined, *, handshake_timeout: int = 10, bufferize: bool = True, limit_type: Literal['none', 'memory', 'count', 'time'] = 'none', limit_capacity: int | float = 10)</code>","text":"<p>             Bases: <code>BaseBufferableStorage</code></p> <p>Implementation of a backend class for working with network and other file storages, based on the fsspec library. As a consequence, in addition to explicitly defined arguments and attributes, the class also accepts argument types and values \u200b\u200bthat are valid for a particular FS implementation (s3fs, local fs, etc.). For the class to work correctly, you must use exclusively asynchronous FS implementations.</p> <p>Parameters:</p> Name Type Description Default <code>engine</code> <code>_FSSpecEngine</code> <p>the engine used to access the repository. In this case, the engine is understood as an initialized instance of the AsyncFileSystem class. Defaults to _EMPTY_FSSPEC.</p> <code>YassUndefined</code> <code>handshake_timeout</code> <code>int</code> <p>timeout for establishing a connection with the backend. Defaults to 10.</p> <code>10</code> <code>bufferize</code> <code>bool</code> <p>data buffering indicator. If False, all data will be constantly merged into the backend without buffering. Defaults to True.</p> <code>True</code> <code>limit_type</code> <code>Literal['none', 'memory', 'count', 'time']</code> <p>type of data storage limit. Defaults to \"none\".</p> <code>'none'</code> <code>limit_capacity</code> <code>int | float</code> <p>limit value of the limiting parameter. For memory limit means the volume in megabytes. Defaults to 10.</p> <code>10</code> Source code in <code>src\\yass\\storages\\blob.py</code> <pre><code>def __init__(\n    self,\n    engine: Undefined | _FSSpecEngine = YassUndefined,\n    *,\n    handshake_timeout: int = 10,\n    bufferize: bool = True,\n    limit_type: Literal[\"none\", \"memory\", \"count\", \"time\"] = \"none\",\n    limit_capacity: int | float = 10,\n):\n    super().__init__(\n        engine,\n        handshake_timeout=handshake_timeout,\n        bufferize=bufferize,\n        limit_type=limit_type,\n        limit_capacity=limit_capacity,\n    )\n</code></pre>"},{"location":"api/blob_storage/#yass.storages.blob.FsBlobStorage.merge_to_backend","title":"<code>merge_to_backend(buf: ContentQueue) -&gt; None</code>  <code>async</code>","text":"<p>The method activates the loading of data to the backend storage from the intermediate buffer if it is available in the implementation.</p> Source code in <code>src\\yass\\storages\\blob.py</code> <pre><code>async def merge_to_backend(self, buf: ContentQueue) -&gt; None:\n    \"\"\"\n    The method activates the loading of data to the backend storage from the intermediate buffer\n    if it is available in the implementation.\n    \"\"\"\n    print(f\"Start merging to backend\")\n    rpp(\n        f\"\u0412\u043d\u0443\u0442\u0440\u0435\u043d\u043d\u044f\u044f \u0431\u043b\u043e\u043a\u0438\u0440\u043e\u0432\u043a\u0430 \u0431\u0443\u0444\u0435\u0440\u0430 \u0443\u0436\u0435 \u0437\u0430\u0445\u0432\u0430\u0447\u0435\u043d\u0430? {buf.internal_lock.locked()}\"\n    )\n    async with buf.block_state() as buf:\n        rpp(\n            \"\u0417\u0430\u0445\u0432\u0430\u0447\u0435\u043d\u0430 \u0432\u043d\u0443\u0442\u0440\u0435\u043d\u043d\u044f\u044f \u0431\u043b\u043e\u043a\u0438\u0440\u043e\u0432\u043a\u0430 \u0431\u0443\u0444\u0435\u0440\u0430 \u0434\u043b\u044f \u0432\u044b\u0433\u0440\u0443\u0437\u043a\u0438 \u043a\u043e\u043d\u0442\u0435\u043d\u0442\u0430.\"\n        )\n        old_content: dict[str, Any] = copy(buf.queue)\n        print(\"Old content\")\n        print(old_content)\n        content_format: str = buf.out_format\n        rpp(f\"\u041e\u0447\u0438\u0449\u0430\u044e \u0441\u043e\u0434\u0435\u0440\u0436\u0438\u043c\u043e\u0435 \u0431\u0443\u0444\u0435\u0440\u0430 {buf} \u043f\u043e\u0441\u043b\u0435 \u043a\u043e\u043f\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f.\")\n        rpp(f\"\u041f\u0435\u0440\u0435\u0445\u043e\u0436\u0443 \u043a \u0437\u0430\u0433\u0440\u0443\u0437\u043a\u0435 \u043a\u043e\u043d\u0442\u0435\u043d\u0442\u0430 \u0432 \u0445\u0440\u0430\u043d\u0438\u043b\u0438\u0449\u0435.\")\n        for path, data in old_content.items():\n            await self.check_path(path, autocreate=True)\n            await self.engine._pipe_file(\n                path, serialize(data, content_format)\n            )\n        rpp(f\"\u0417\u0430\u0432\u0435\u0440\u0448\u0438\u043b \u0437\u0430\u0433\u0440\u0443\u0437\u043a\u0443 \u043a\u043e\u043d\u0442\u0435\u043a\u0442\u0430 \u0432 \u0445\u0440\u0430\u043d\u0438\u043b\u0438\u0449\u0435.\")\n        buf.reset()\n        await self._recalc_counters()\n\n    rpp(f\"\u041f\u0440\u043e\u0446\u0435\u0441\u0441 \u0432\u044b\u0433\u0440\u0443\u0437\u043a\u0438 \u0434\u0430\u043d\u043d\u044b\u0445 \u0432 \u0445\u0440\u0430\u043d\u0438\u043b\u0438\u0449\u0435 \u0437\u0430\u0432\u0435\u0440\u0448\u0435\u043d.\")\n</code></pre>"},{"location":"api/blob_storage/#service-classes-and-utilities","title":"Service classes and utilities","text":""},{"location":"api/blob_storage/#yass.storages.blob.check_path","title":"<code>check_path(engine: _FSSpecEngine, path: str, *, autocreate: bool = True) -&gt; bool</code>","text":"<p>A function to check the existence of a path to a file or folder. Although the function is synchronous, it organizes the execution of the asynchronous storage engine in a separate thread.</p> <p>Parameters:</p> Name Type Description Default <code>engine</code> <code>_FSSpecEngine</code> <p>asynchronous storage engine.</p> required <code>path</code> <code>str</code> <p>the path to be checked</p> required <code>autocreate</code> <code>bool</code> <p>a flag that determines whether to create an object according to the path automatically. Defaults to True.</p> <code>True</code> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>an indicator of the existence of a path.</p> Source code in <code>src\\yass\\storages\\blob.py</code> <pre><code>def check_path(\n    engine: _FSSpecEngine, path: str, *, autocreate: bool = True\n) -&gt; bool:\n    \"\"\"\n    A function to check the existence of a path to a file or folder.\n    Although the function is synchronous, it organizes the execution of the asynchronous storage engine in a separate thread.\n\n    Args:\n        engine (_FSSpecEngine): asynchronous storage engine.\n        path (str): the path to be checked\n        autocreate (bool): a flag that determines whether to create an object according to the path automatically. Defaults to True.\n\n    Returns:\n        bool: an indicator of the existence of a path.\n    \"\"\"\n    status: bool = engine.exists(path)\n    if (res := not status) and autocreate:\n        mk_path(engine, path)\n        return res\n    else:\n        return status\n</code></pre>"},{"location":"api/blob_storage/#yass.storages.blob.create_fsspec_engine","title":"<code>create_fsspec_engine(proto: str, *, engine_kwargs: dict[str, Any]) -&gt; _FSSpecEngine</code>","text":"<p>The factory of data storage engines. Uses fsspec under the hood. Returns an error if the engine does not support asynchronous execution of operations.</p> <p>Parameters:</p> Name Type Description Default <code>proto</code> <code>str</code> <p>a string with the name of the storage engine protocol. For a list of supported protocols         see fsspec known implementations.</p> required <code>engine_kwargs</code> <code>dict[str, Any]</code> <p>a dictionary with storage engine parameters. For mandatory and optional parameters                             see the corresponding implementation of the fsspec protocol.</p> required <p>Returns:</p> Name Type Description <code>_FSSpecEngine</code> <code>_FSSpecEngine</code> <p>asynchronous implementation of the storage engine.</p> Source code in <code>src\\yass\\storages\\blob.py</code> <pre><code>@engine_factory(FsBlobStorage)\ndef create_fsspec_engine(\n    proto: str, *, engine_kwargs: dict[str, Any]\n) -&gt; _FSSpecEngine:\n    \"\"\"\n    The factory of data storage engines. Uses fsspec under the hood.\n    Returns an error if the engine does not support asynchronous execution of operations.\n\n    Args:\n        proto (str): a string with the name of the storage engine protocol. For a list of supported protocols\n                    see fsspec known implementations.\n        engine_kwargs (dict[str, Any]): a dictionary with storage engine parameters. For mandatory and optional parameters\n                                        see the corresponding implementation of the fsspec protocol.\n\n    Returns:\n        _FSSpecEngine: asynchronous implementation of the storage engine.\n    \"\"\"\n    _storage: _StorageFabric = get_filesystem_class(proto)\n    if not issubclass(_storage, _FSSpecEngine):\n        msg = \"\u0414\u043e\u043f\u0443\u0441\u043a\u0430\u0435\u0442\u0441\u044f \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u0435 \u0442\u043e\u043b\u044c\u043a\u043e \u0430\u0441\u0438\u043d\u0445\u0440\u043e\u043d\u043d\u044b\u0445 \u0434\u0432\u0438\u0436\u043a\u043e\u0432.\"\n        raise RuntimeError(msg) from None\n    engine = _storage(**engine_kwargs)\n    return engine\n</code></pre>"},{"location":"api/blob_storage/#yass.storages.blob.download","title":"<code>download(engine: _FSSpecEngine, path: str) -&gt; bytes</code>","text":"<p>The function of downloading content to the repository. Although the function is synchronous, it organizes the execution of the asynchronous storage engine in a separate thread.</p> <p>Parameters:</p> Name Type Description Default <code>engine</code> <code>_FSSpecEngine</code> <p>asynchronous storage engine.</p> required <code>path</code> <code>str</code> <p>the path to save the content.</p> required <p>Returns:</p> Name Type Description <code>bytes</code> <code>bytes</code> <p>content in byte (serialized) representation.</p> Source code in <code>src\\yass\\storages\\blob.py</code> <pre><code>def download(engine: _FSSpecEngine, path: str) -&gt; bytes:\n    \"\"\"\n    The function of downloading content to the repository.\n    Although the function is synchronous, it organizes the execution of the asynchronous storage engine in a separate thread.\n\n    Args:\n        engine (_FSSpecEngine): asynchronous storage engine.\n        path (str): the path to save the content.\n\n    Returns:\n        bytes: content in byte (serialized) representation.\n    \"\"\"\n    content: bytes = cast(bytes, engine.cat(path))\n    return content\n</code></pre>"},{"location":"api/blob_storage/#yass.storages.blob.mk_path","title":"<code>mk_path(engine: _FSSpecEngine, path: str) -&gt; None</code>","text":"<p>A function for creating a folder or file in the storage. Although the function is synchronous, it organizes the execution of the asynchronous storage engine in a separate thread.</p> <p>Parameters:</p> Name Type Description Default <code>engine</code> <code>_FSSpecEngine</code> <p>asynchronous storage engine.</p> required <code>path</code> <code>str</code> <p>the path to use to create a folder or file.</p> required Source code in <code>src\\yass\\storages\\blob.py</code> <pre><code>def mk_path(engine: _FSSpecEngine, path: str) -&gt; None:\n    \"\"\"\n    A function for creating a folder or file in the storage.\n    Although the function is synchronous, it organizes the execution of the asynchronous storage engine in a separate thread.\n\n    Args:\n        engine (_FSSpecEngine): asynchronous storage engine.\n        path (str): the path to use to create a folder or file.\n    \"\"\"\n    try:\n        engine.mkdir(Path(path).parts[0])\n    except FileExistsError:\n        engine.touch(path)  # type: ignore\n</code></pre>"},{"location":"api/blob_storage/#yass.storages.blob.read","title":"<code>read(engine: _FSSpecEngine, path: str) -&gt; Any</code>","text":"<p>A function for reading content from storage. Although the function is synchronous, it organizes the execution of the asynchronous storage engine in a separate thread.</p> <p>Parameters:</p> Name Type Description Default <code>engine</code> <code>_FSSpecEngine</code> <p>asynchronous storage engine.</p> required <code>path</code> <code>str</code> <p>the path to download the content</p> required <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>an instance of the data object. The type of the returned object depends on the deserialization</p> <code>Any</code> <p>function registered for the corresponding data format.</p> Source code in <code>src\\yass\\storages\\blob.py</code> <pre><code>def read(engine: _FSSpecEngine, path: str) -&gt; Any:\n    \"\"\"\n    A function for reading content from storage.\n    Although the function is synchronous, it organizes the execution of the asynchronous storage engine in a separate thread.\n\n    Args:\n        engine (_FSSpecEngine): asynchronous storage engine.\n        path (str): the path to download the content\n\n    Returns:\n        Any: an instance of the data object. The type of the returned object depends on the deserialization\n        function registered for the corresponding data format.\n    \"\"\"\n    content: bytes = download(engine, path)\n    extension: str = Path(path).suffix.lstrip(\".\")\n    dataobj = deserialize(content, extension)\n    return dataobj\n</code></pre>"},{"location":"api/blob_storage/#yass.storages.blob.upload","title":"<code>upload(engine: _FSSpecEngine, content: bytes, path: str) -&gt; None</code>","text":"<p>The function of uploading content to the repository. Although the function is synchronous, it organizes the execution of the asynchronous storage engine in a separate thread.</p> <p>Parameters:</p> Name Type Description Default <code>engine</code> <code>_FSSpecEngine</code> <p>asynchronous storage engine.</p> required <code>content</code> <code>bytes</code> <p>serialized content.</p> required <code>path</code> <code>str</code> <p>the path to save the content.</p> required Source code in <code>src\\yass\\storages\\blob.py</code> <pre><code>def upload(engine: _FSSpecEngine, content: bytes, path: str) -&gt; None:\n    \"\"\"\n    The function of uploading content to the repository.\n    Although the function is synchronous, it organizes the execution of the asynchronous storage engine in a separate thread.\n\n    Args:\n        engine (_FSSpecEngine): asynchronous storage engine.\n        content (bytes): serialized content.\n        path (str): the path to save the content.\n    \"\"\"\n    engine.pipe_file(path, content)\n</code></pre>"},{"location":"api/common/","title":"Common objects","text":""},{"location":"api/common/#yass.contentio.INPUT_MAP","title":"<code>INPUT_MAP = _InputMap()</code>  <code>module-attribute</code>","text":"<p>Dict-like repository of data input (deserialization) functions. The key is the name of the data type in the form of a string, the value is callable, assigned as a handler for the corresponding data type.</p>"},{"location":"api/common/#yass.contentio.OUTPUT_MAP","title":"<code>OUTPUT_MAP = _OutputMap()</code>  <code>module-attribute</code>","text":"<p>Dict-like repository of data output (serialization) functions. The key is the name of the data type in the form of a string, the value is callable, assigned as a handler for the corresponding data type.</p>"},{"location":"api/contentio/","title":"ContentIO module","text":""},{"location":"api/contentio/#yass.contentio.IOBoundPipeline","title":"<code>IOBoundPipeline</code>  <code>dataclass</code>","text":"<p>The class is responsible for registering handler functions and applying them to incoming data. Creates a separate thread for processing to avoid blocking the event loop. The data is processed in batches, the size of which depends on the settings of the resource involved and the current load on the resource. Each pipeline is inextricably linked to an I/O context, and for any such context there can only be one pipeline.</p> <p>Attributes:</p> Name Type Description <code>io_context</code> <code>IOContext</code> <p>an I/O context object to which the pipeline will be associated.</p> <code>functions</code> <code>list[Callable]</code> <p>list of registered functions. The order of the functions in the list directly indicates the order in which they are tried on.</p> <code>on_error</code> <code>Callable</code> <p>Exception catching function. Can be used for specific exception handling. By default, it is a lambda function that returns                 any object passed to it unchanged.</p> <code>data_filter</code> <code>Callable</code> <p>A function for filtering content for invalid blocks. Registered via the appropriate method. By default, it is a lambda function                 that returns any object passed to it unchanged.</p> <p>Parameters:</p> Name Type Description Default <code>io_context</code> <code>IOContext</code> <p>an I/O context object to which the pipeline will be associated.</p> required <code>functions</code> <code>list[Callable]</code> <p>list of registered functions. The order of the functions in the list directly indicates the order in which they are tried on.</p> <code>field(default_factory=list)</code> <code>on_error</code> <code>Callable</code> <p>Exception catching function. Can be used for specific exception handling. By default, it is a lambda function that returns                 any object passed to it unchanged.</p> <code>lambda : x</code> <code>data_filter</code> <code>Callable</code> <p>A function for filtering content for invalid blocks. Registered via the appropriate method. By default, it is a lambda function                 that returns any object passed to it unchanged.</p> <code>lambda : True</code>"},{"location":"api/contentio/#yass.contentio.IOBoundPipeline.change_order","title":"<code>change_order(old_idx: int, new_idx: int) -&gt; None</code>","text":"<p>The method changes the position of the function in the pipeline.</p> <p>Parameters:</p> Name Type Description Default <code>old_idx</code> <code>int</code> <p>old position.</p> required <code>new_idx</code> <code>int</code> <p>new position.</p> required Source code in <code>src\\yass\\contentio\\contentio.py</code> <pre><code>def change_order(self, old_idx: int, new_idx: int) -&gt; None:\n    \"\"\"\n    The method changes the position of the function in the pipeline.\n\n    Args:\n        old_idx (int): old position.\n        new_idx (int): new position.\n    \"\"\"\n    func: Callable = self.functions.pop(old_idx)\n    self.functions.insert(new_idx, func)\n</code></pre>"},{"location":"api/contentio/#yass.contentio.IOBoundPipeline.content_filter","title":"<code>content_filter(func: Callable[..., bool]) -&gt; None</code>","text":"<p>The method registers a function that is used to filter content. Such a function must return a boolean.</p> <p>Parameters:</p> Name Type Description Default <code>func</code> <code>Callable[..., bool]</code> <p>any function containing user-relevant logic for validating content.</p> required Source code in <code>src\\yass\\contentio\\contentio.py</code> <pre><code>def content_filter(self, func: Callable[..., bool]) -&gt; None:\n    \"\"\"\n    The method registers a function that is used to filter content. Such a function must return a boolean.\n\n    Args:\n        func (Callable[..., bool]): any function containing user-relevant logic for validating content.\n    \"\"\"\n    self.data_filter = func\n</code></pre>"},{"location":"api/contentio/#yass.contentio.IOBoundPipeline.run_transform","title":"<code>run_transform(dataobj: Iterable[Any]) -&gt; AsyncIterator[Future]</code>  <code>async</code>","text":"<p>The method starts the data processing process. At this stage, content is validated and filtered, as well as its transformation in a separate thread.</p> <p>Parameters:</p> Name Type Description Default <code>dataobj</code> <code>Iterable[Any]</code> <p>batch with data objects of any type.</p> required <p>Yields:</p> Type Description <code>AsyncIterator[Future]</code> <p>AsyncIterator[Future]: asyncio futures (in the form of an asynchronous iterator) to wait for the processing of a data batch to complete.</p> Source code in <code>src\\yass\\contentio\\contentio.py</code> <pre><code>@asynccontextmanager\nasync def run_transform(\n    self, dataobj: Iterable[Any]\n) -&gt; AsyncIterator[Future]:\n    \"\"\"\n    The method starts the data processing process. At this stage, content is validated and filtered,\n    as well as its transformation in a separate thread.\n\n    Args:\n        dataobj (Iterable[Any]): batch with data objects of any type.\n\n    Yields:\n        AsyncIterator[Future]: asyncio futures (in the form of an asynchronous iterator) to wait for the processing of a data batch to complete.\n    \"\"\"\n    valid_content: list[Any] = [\n        data for data in dataobj if self.data_filter(data)\n    ]\n    try:\n        coros = []\n        for data in valid_content:\n            coro: Coroutine[Any, None, Any] = to_thread(\n                reduce, lambda arg, func: func(arg), self.functions, data\n            )\n            coros.append(coro)\n        yield gather(*coros)\n    except Exception as exc:\n        res: Any = self.on_error(exc)\n        if isinstance(res, Exception):\n            raise res\n</code></pre>"},{"location":"api/contentio/#yass.contentio.IOBoundPipeline.show_pipeline","title":"<code>show_pipeline() -&gt; str</code>","text":"<p>The method returns a string describing the chain of function calls in the pipeline.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>a chain of function calls as a string.</p> Source code in <code>src\\yass\\contentio\\contentio.py</code> <pre><code>def show_pipeline(self) -&gt; str:\n    \"\"\"\n    The method returns a string describing the chain of function calls in the pipeline.\n\n    Returns:\n        str: a chain of function calls as a string.\n    \"\"\"\n    ctx: IOContext = self.io_context\n    pipe: list[str] = [\n        f\"{order}: {func.__name__}\"\n        for order, func in enumerate(self.functions)\n    ]\n    return \" -&gt; \".join(pipe) + f\" for {ctx.in_format}.\"\n</code></pre>"},{"location":"api/contentio/#yass.contentio.IOBoundPipeline.step","title":"<code>step(order: int, *, extra_kwargs: dict[str, Any] = {}) -&gt; Callable</code>","text":"<p>Method for registering a handler function.</p> <p>Parameters:</p> Name Type Description Default <code>order</code> <code>int</code> <p>Position of the function in the pipeline. This argument ultimately determines the order in         which handlers are applied to the data.</p> required <code>extra_kwargs</code> <code>dict[str, Any]</code> <p>Additional handler function arguments. Under the hood, _update_sign is applied. Defaults to {}.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>Callable</code> <code>Callable</code> <p>function registered as a data handler without modification.</p> Source code in <code>src\\yass\\contentio\\contentio.py</code> <pre><code>def step(\n    self, order: int, *, extra_kwargs: dict[str, Any] = {}\n) -&gt; Callable:\n    \"\"\"\n    Method for registering a handler function.\n\n    Args:\n        order (int): Position of the function in the pipeline. This argument ultimately determines the order in\n                    which handlers are applied to the data.\n        extra_kwargs (dict[str, Any], optional): Additional handler function arguments. Under the hood, _update_sign is applied. Defaults to {}.\n\n    Returns:\n        Callable: function registered as a data handler without modification.\n    \"\"\"\n\n    def wrapper(func):\n        self._check_sig(func)\n        updated_func: Callable = update_sign(\n            func, extra_kwargs=extra_kwargs\n        )\n        self.functions.insert(order - 1, updated_func)\n        return func\n\n    return wrapper\n</code></pre>"},{"location":"api/contentio/#yass.contentio.IOContext","title":"<code>IOContext(*, in_format: str, out_format: str, storage: BaseBufferableStorage)</code>","text":"<p>The I/O context class specifies the format of incoming and outgoing data (which may or may not be the same - it all depends on the user's tasks) and also where the corresponding data is stored. Instances of this class are required to create requests for resources and register data processing pipelines. The context object also stores information about the data path pattern.</p> <p>Attributes:</p> Name Type Description <code>in_format</code> <code>str</code> <p>format of incoming data.</p> <code>out_format</code> <code>str</code> <p>the format in which the data should be saved.</p> <code>storage</code> <code>BaseBufferableStorage</code> <p>storage in which the data will be stored.</p> <code>path_temp</code> <code>PathTemplate</code> <p>path generator for storing data in storage. See PathTemplate for details.</p> <code>pipeline</code> <code>IOBoundPipeline</code> <p>a pipeline object initiated within the current I/O context. See IOBoundPipeline for details.</p> <p>Parameters:</p> Name Type Description Default <code>in_format</code> <code>str</code> <p>format of incoming data.</p> required <code>out_format</code> <code>str</code> <p>the format in which the data should be saved.</p> required <code>storage</code> <code>BaseBufferableStorage</code> <p>storage in which the data will be stored.</p> required Source code in <code>src\\yass\\contentio\\contentio.py</code> <pre><code>def __init__(\n    self,\n    *,\n    in_format: str,\n    out_format: str,\n    storage: BaseBufferableStorage,\n) -&gt; None:\n    \"\"\"\n    Args:\n        in_format (str): format of incoming data.\n        out_format (str): the format in which the data should be saved.\n        storage (BaseBufferableStorage): storage in which the data will be stored.\n    \"\"\"\n    self.in_format: str = in_format\n    self.out_format: str = out_format\n    self._check_io()\n    self.storage: BaseBufferableStorage = storage\n    self.path_temp: PathTemplate | Undefined = YassUndefined\n    self.pipeline: IOBoundPipeline | Undefined = YassUndefined\n</code></pre>"},{"location":"api/contentio/#yass.contentio.IOContext.attache_pathgenerator","title":"<code>attache_pathgenerator(is_local: bool = False) -&gt; PathTemplate</code>","text":"<p>The method creates and binds an instance of the data path template.</p> <p>Returns:</p> Name Type Description <code>PathTemplate</code> <code>PathTemplate</code> <p>data path template instance.</p> Source code in <code>src\\yass\\contentio\\contentio.py</code> <pre><code>def attache_pathgenerator(self, is_local: bool = False) -&gt; PathTemplate:\n    \"\"\"\n    The method creates and binds an instance of the data path template.\n\n    Returns:\n        PathTemplate: data path template instance.\n    \"\"\"\n    path_temp = PathTemplate(is_local)\n    self.path_temp = path_temp\n    return path_temp\n</code></pre>"},{"location":"api/contentio/#yass.contentio.IOContext.attache_pipeline","title":"<code>attache_pipeline() -&gt; IOBoundPipeline</code>","text":"<p>Method creates and links a data processing pipeline.</p> <p>Returns:</p> Name Type Description <code>IOBoundPipeline</code> <code>IOBoundPipeline</code> <p>pipeline instance.</p> Source code in <code>src\\yass\\contentio\\contentio.py</code> <pre><code>def attache_pipeline(self) -&gt; IOBoundPipeline:\n    \"\"\"\n    Method creates and links a data processing pipeline.\n\n    Returns:\n        IOBoundPipeline: pipeline instance.\n    \"\"\"\n    self.pipeline = IOBoundPipeline(self)\n    return self.pipeline\n</code></pre>"},{"location":"api/contentio/#yass.contentio.IOContext.out_path","title":"<code>out_path: str</code>  <code>property</code>","text":"<p>Path to save data with extension.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>path to the data in the storage.</p>"},{"location":"api/contentio/#yass.contentio.IOContext.update_ctx","title":"<code>update_ctx(*, in_format: str | None = None, out_format: str | None = None, storage: BaseBufferableStorage | None = None) -&gt; Self</code>","text":"<p>The method updates context attributes.</p> Source code in <code>src\\yass\\contentio\\contentio.py</code> <pre><code>def update_ctx(\n    self,\n    *,\n    in_format: str | None = None,\n    out_format: str | None = None,\n    storage: BaseBufferableStorage | None = None,\n) -&gt; Self:\n    \"\"\"\n    The method updates context attributes.\n    \"\"\"\n    default_params = vars(self)\n    kwds: dict[str, Any] = {\n        k: v for k, v in locals().items() if v is not None\n    }\n    kwds.pop(\"self\")\n    default_params.update(kwds)\n    for attr, value in default_params.items():\n        setattr(self, attr, value)\n    return self\n</code></pre>"},{"location":"api/contentio/#yass.contentio.PathSegment","title":"<code>PathSegment</code>  <code>dataclass</code>","text":"<p>Is a representation of the path fragment where the retrieved data is stored. A collection of PathSegments represent the full path to the data storage location.</p> <p>Parameters:</p> Name Type Description Default <code>concatenator</code> <code>str</code> <p>literal through which parts of the segment will be combined.</p> required <code>segment_order</code> <code>int</code> <p>The position that the segment will occupy along the path.</p> <code>field(compare=True)</code> <code>segment_parts</code> <code>list[str | Callable]</code> <p>parts of the segment. There can be both callables that will be called to format a string                                     (for example, functions from the datetime package), and standard strings. Defaults to [].</p> <code>field(default_factory=list)</code> <p>Attributes:</p> Name Type Description <code>concatenator</code> <code>str</code> <p>literal through which parts of the segment will be combined.</p> <code>segment_order</code> <code>int</code> <p>The position that the segment will occupy along the path.</p> <code>segment_parts</code> <code>list[str | Callable]</code> <p>parts of the segment. There can be both callables that will be called to format a string                                     (for example, functions from the datetime package), and standard strings.</p>"},{"location":"api/contentio/#yass.contentio.PathSegment.add_part","title":"<code>add_part(*part: str | Callable) -&gt; None</code>","text":"<p>The method adds an arbitrary number of elements to the list of parts. The order of the elements matters to get the desired look of the path string.</p> <p>Parameters:</p> Name Type Description Default <code>part</code> <code>str | Callable</code> <p>strings or any functions. The argument accepts an unlimited number of parts.</p> <code>()</code> Source code in <code>src\\yass\\contentio\\contentio.py</code> <pre><code>def add_part(self, *part: str | Callable) -&gt; None:\n    \"\"\"\n    The method adds an arbitrary number of elements to the list of parts.\n    The order of the elements matters to get the desired look of the path string.\n\n    Args:\n        part (str | Callable): strings or any functions. The argument accepts an unlimited number of parts.\n    \"\"\"\n    self.segment_parts.extend(part)\n</code></pre>"},{"location":"api/contentio/#yass.contentio.PathSegment.change_concat","title":"<code>change_concat(concatenator: str) -&gt; Self</code>","text":"<p>The method replaces the concatenator with a new one.</p> <p>Parameters:</p> Name Type Description Default <code>concatenator</code> <code>str</code> <p>any string.</p> required <p>Returns:</p> Name Type Description <code>Self</code> <code>Self</code> <p>segment with updated concatenator.</p> Source code in <code>src\\yass\\contentio\\contentio.py</code> <pre><code>def change_concat(self, concatenator: str) -&gt; Self:\n    \"\"\"\n    The method replaces the concatenator with a new one.\n\n    Args:\n        concatenator (str): any string.\n\n    Returns:\n        Self: segment with updated concatenator.\n    \"\"\"\n    kwds: dict[str, Any] = locals()\n    return replace(kwds.pop(\"self\"), **kwds)\n</code></pre>"},{"location":"api/contentio/#yass.contentio.PathTemplate","title":"<code>PathTemplate(is_local: bool = False)</code>","text":"<p>The class manages a collection of segments and is responsible for generating the full path to the data as a string. When generating the final path string, it takes into account the environment for which the path is being generated. The generated paths are the address where the data is stored in the storage.</p> <p>Attributes:</p> Name Type Description <code>segments</code> <code>list[PathSegment]</code> <p>list of path segments.</p> <code>is_local</code> <code>bool</code> <p>if set to True, then PathTemplate will form the path using the operating system path separator.</p> <p>Parameters:</p> Name Type Description Default <code>is_local</code> <code>bool</code> <p>if set to True, then PathTemplate will form the path using the operating system path separator. Defaults to False.</p> <code>False</code> Source code in <code>src\\yass\\contentio\\contentio.py</code> <pre><code>def __init__(self, is_local: bool = False) -&gt; None:\n    \"\"\"\n    Args:\n        is_local (bool, optional): if set to True, then PathTemplate will form the path using the operating system path separator. Defaults to False.\n    \"\"\"\n    self.segments: list[PathSegment] = list()\n    self.is_local: bool = is_local\n</code></pre>"},{"location":"api/contentio/#yass.contentio.PathTemplate.add_segment","title":"<code>add_segment(concatenator: str, segment_order: int, segment_parts: list[str | Callable[..., Any]]) -&gt; None</code>","text":"<p>A factory method that allows you to generate a path segment. The new segment is immediately added to the class field and is not returned. For a description of the arguments, see PathSegment.</p> Source code in <code>src\\yass\\contentio\\contentio.py</code> <pre><code>def add_segment(\n    self,\n    concatenator: str,\n    segment_order: int,\n    segment_parts: list[str | Callable[..., Any]],\n) -&gt; None:\n    \"\"\"\n    A factory method that allows you to generate a path segment.\n    The new segment is immediately added to the class field and is not returned.\n    For a description of the arguments, see PathSegment.\n    \"\"\"\n    self.segments.append(\n        PathSegment(concatenator, segment_order, segment_parts)\n    )\n</code></pre>"},{"location":"api/contentio/#yass.contentio.PathTemplate.render_path","title":"<code>render_path(ext: str = '') -&gt; str</code>","text":"<p>Generates and returns the data path. The optional ext parameter is used to add an extension to the path.</p> <p>Parameters:</p> Name Type Description Default <code>ext</code> <code>str</code> <p>data format identifier. Defaults to \"\".</p> <code>''</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>path to data with or without extension.</p> Source code in <code>src\\yass\\contentio\\contentio.py</code> <pre><code>def render_path(self, ext: str = \"\") -&gt; str:\n    \"\"\"\n    Generates and returns the data path. The optional ext parameter is used to add an extension to the path.\n\n    Args:\n        ext (str, optional): data format identifier. Defaults to \"\".\n\n    Returns:\n        str: path to data with or without extension.\n    \"\"\"\n    self.segments.sort(key=lambda x: x.segment_order)\n    nonull_segments = map(\n        lambda x: str(x),\n        filter(lambda x: x.__str__() != \"\", self.segments),\n    )\n    nonull_segments: Iterable[str] = cast(Iterable[str], nonull_segments)\n    if self.is_local or (platform == \"linux\" and not self.is_local):\n        sep: str = os.sep\n    elif platform == \"win32\" and not self.is_local:\n        sep = cast(str, os.altsep)\n    return (\n        sep.join(nonull_segments) + f\".{ext}\"\n        if ext\n        else sep.join(nonull_segments)\n    )\n</code></pre>"},{"location":"api/contentio/#yass.contentio.allowed_datatypes","title":"<code>allowed_datatypes(*, display: bool = False) -&gt; list[_DataTypeInfo]</code>","text":"<p>Returns the currently registered and therefore available for processing data formats.</p> <p>Parameters:</p> Name Type Description Default <code>display</code> <code>bool</code> <p>Outputting a list of data formats to the console. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <code>list[_DataTypeInfo]</code> <p>list[_DataTypeInfo]: list of available data formats.</p> Source code in <code>src\\yass\\contentio\\contentio.py</code> <pre><code>def allowed_datatypes(*, display: bool = False) -&gt; list[_DataTypeInfo]:\n    \"\"\"\n    Returns the currently registered and therefore available for processing data formats.\n\n    Args:\n        display (bool, optional): Outputting a list of data formats to the console. Defaults to False.\n\n    Returns:\n        list[_DataTypeInfo]: list of available data formats.\n    \"\"\"\n    ndrows: list[_DataTypeInfo] = [_datatype_info(k) for k in INPUT_MAP]\n    if display:\n        for row in ndrows:\n            pprint(row, depth=2, sort_dicts=False)\n    return ndrows\n</code></pre>"},{"location":"api/contentio/#yass.contentio.create_datatype","title":"<code>create_datatype(*, format_name: str, input_func: Callable, extra_args_in: dict = {}, output_func: Callable, extra_args_out: dict = {}, replace: bool = False) -&gt; None</code>","text":"<p>Registers a new data format and functions for processing content of the specified format.</p> <p>Parameters:</p> Name Type Description Default <code>format_name</code> <code>str</code> <p>Target data format.</p> required <code>input_func</code> <code>Callable</code> <p>Function for deserializing data.</p> required <code>output_func</code> <code>Callable</code> <p>Function for serializing data.</p> required <code>extra_args_in</code> <code>dict</code> <p>Values of deserializing function arguments that need to be bound instead of the default ones. Defaults to {}.</p> <code>{}</code> <code>extra_args_out</code> <code>dict</code> <p>the same for the serialization function.. Defaults to {}.</p> <code>{}</code> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>thrown if the data format is already registered.</p> Source code in <code>src\\yass\\contentio\\contentio.py</code> <pre><code>def create_datatype(\n    *,\n    format_name: str,\n    input_func: Callable,\n    extra_args_in: dict = {},\n    output_func: Callable,\n    extra_args_out: dict = {},\n    replace: bool = False,\n) -&gt; None:\n    \"\"\"\n    Registers a new data format and functions for processing content of the specified format.\n\n    Args:\n        format_name (str): Target data format.\n        input_func (Callable): Function for deserializing data.\n        output_func (Callable): Function for serializing data.\n        extra_args_in (dict, optional): Values of deserializing function arguments that need to be bound instead of the default ones. Defaults to {}.\n        extra_args_out (dict, optional): the same for the serialization function.. Defaults to {}.\n\n    Raises:\n        RuntimeError: thrown if the data format is already registered.\n    \"\"\"\n    if (\n        not format_name in INPUT_MAP\n        or not format_name in OUTPUT_MAP\n        or replace\n    ):\n        reg_input(format_name, input_func, extra_args_in)\n        reg_output(format_name, output_func, extra_args_out)\n    else:\n        msg = \"\u0414\u0430\u043d\u043d\u044b\u0439 \u0442\u0438\u043f \u0434\u0430\u043d\u043d\u044b\u0445 \u0443\u0436\u0435 \u0437\u0430\u0440\u0435\u0433\u0438\u0441\u0442\u0440\u0438\u0440\u043e\u0432\u0430\u043d\"\n        raise RuntimeError(msg)\n</code></pre>"},{"location":"api/contentio/#yass.contentio.create_io_context","title":"<code>create_io_context(*, in_format: str, out_format: str, storage: BaseBufferableStorage) -&gt; IOContext</code>","text":"<p>Module level function for creating IO context instances. Accepts the arguments necessary to initialize objects of this type.</p> <p>Returns:</p> Name Type Description <code>IOContext</code> <code>IOContext</code> <p>new instance of IOContext.</p> Source code in <code>src\\yass\\contentio\\contentio.py</code> <pre><code>def create_io_context(\n    *, in_format: str, out_format: str, storage: BaseBufferableStorage\n) -&gt; IOContext:\n    \"\"\"\n    Module level function for creating IO context instances. Accepts the arguments necessary to initialize objects of this type.\n\n    Returns:\n        IOContext: new instance of IOContext.\n    \"\"\"\n    kwargs: dict[str, Any] = {k: v for k, v in locals().items()}\n    ctx = IOContext(**kwargs)\n    return ctx\n</code></pre>"},{"location":"api/contentio/#yass.contentio.deserialize","title":"<code>deserialize(content: bytes, format: str, extra_args: dict[str, Any] = {}) -&gt; Any</code>","text":"<p>Deserializes byte content into an object of the specified format.</p> <p>Parameters:</p> Name Type Description Default <code>content</code> <code>bytes</code> <p>Content received in byte representation.</p> required <code>format</code> <code>str</code> <p>The format of the data that the resource provides.</p> required <code>extra_args</code> <code>dict[str, Any]</code> <p>Values of function arguments that need to be bound instead of the default ones. Defaults to {}.</p> <code>{}</code> <p>Raises:</p> Type Description <code>KeyError</code> <p>thrown if there is no registered function of the given format.</p> <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>data object of any type (for example, pandas df, polars df, dict from json, etc.).</p> Source code in <code>src\\yass\\contentio\\contentio.py</code> <pre><code>def deserialize(\n    content: bytes, format: str, extra_args: dict[str, Any] = {}\n) -&gt; Any:\n    \"\"\"\n    Deserializes byte content into an object of the specified format.\n\n    Args:\n        content (bytes): Content received in byte representation.\n        format (str): The format of the data that the resource provides.\n        extra_args (dict[str, Any], optional): Values of function arguments that need to be bound instead of the default ones. Defaults to {}.\n\n    Raises:\n        KeyError: thrown if there is no registered function of the given format.\n\n    Returns:\n        Any: data object of any type (for example, pandas df, polars df, dict from json, etc.).\n    \"\"\"\n    func: Callable[[bytes, dict], Any] = INPUT_MAP[format]\n    dataobj: Any = func(content, **extra_args)\n    return dataobj\n</code></pre>"},{"location":"api/contentio/#yass.contentio.reg_input","title":"<code>reg_input(extension: str, func: Callable, extra_args: dict[str, Any] = {}) -&gt; None</code>","text":"<p>Registers a data deserialization function.</p> <p>Parameters:</p> Name Type Description Default <code>extension</code> <code>str</code> <p>The data format for which the function is intended (for example, json, csv, etc.).</p> required <code>func</code> <code>Callable</code> <p>Function for deserializing data.</p> required <code>extra_args</code> <code>dict[str, Any]</code> <p>Values of function arguments that need to be bound instead of the default ones. Defaults to {}.</p> <code>{}</code> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>thrown if the function fails validation. The error message indicates which part of the function is invalid.</p> Source code in <code>src\\yass\\contentio\\contentio.py</code> <pre><code>def reg_input(\n    extension: str, func: Callable, extra_args: dict[str, Any] = {}\n) -&gt; None:\n    \"\"\"\n    Registers a data deserialization function.\n\n    Args:\n        extension (str): The data format for which the function is intended (for example, json, csv, etc.).\n        func (Callable): Function for deserializing data.\n        extra_args (dict[str, Any], optional): Values of function arguments that need to be bound instead of the default ones. Defaults to {}.\n\n    Raises:\n        RuntimeError: thrown if the function fails validation. The error message indicates which part of the function is invalid.\n    \"\"\"\n    if check_input_sig(func):\n        func = update_sign(func, extra_args) if extra_args else func\n    else:\n        raise RuntimeError(\n            \"\u041f\u0435\u0440\u0432\u044b\u043c \u0430\u0440\u0433\u0443\u043c\u0435\u043d\u0442\u043e\u043c \u0444\u0443\u043d\u043a\u0446\u0438\u0438 \u0432\u0432\u043e\u0434\u0430 \u0434\u043e\u043b\u0436\u0435\u043d \u0431\u044b\u0442\u044c \u043e\u0431\u044a\u0435\u043a\u0442 \u0442\u0438\u043f\u0430 bytes\"\n        ) from None\n    INPUT_MAP[extension] = func\n</code></pre>"},{"location":"api/contentio/#yass.contentio.reg_output","title":"<code>reg_output(extension, func: Callable, extra_args: dict[str, Any] = {}) -&gt; None</code>","text":"<p>Registers a data serialization function.</p> <p>Parameters:</p> Name Type Description Default <code>extension</code> <code>str</code> <p>The data format for which the function is intended (for example, json, csv, etc.).</p> required <code>func</code> <code>Callable</code> <p>Function for deserializing data.</p> required <code>extra_args</code> <code>dict[str, Any]</code> <p>Values of function arguments that need to be bound instead of the default ones. Defaults to {}.</p> <code>{}</code> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>Thrown if the function fails validation. The error message indicates which part of the function is invalid.</p> Source code in <code>src\\yass\\contentio\\contentio.py</code> <pre><code>def reg_output(\n    extension, func: Callable, extra_args: dict[str, Any] = {}\n) -&gt; None:\n    \"\"\"\n    Registers a data serialization function.\n\n    Args:\n        extension (str): The data format for which the function is intended (for example, json, csv, etc.).\n        func (Callable): Function for deserializing data.\n        extra_args (dict[str, Any], optional): Values of function arguments that need to be bound instead of the default ones. Defaults to {}.\n\n    Raises:\n        RuntimeError: Thrown if the function fails validation. The error message indicates which part of the function is invalid.\n    \"\"\"\n    if check_output_sig(func):\n        func = update_sign(func, extra_args) if extra_args else func\n    else:\n        raise RuntimeError(\n            \"\u0412\u0442\u043e\u0440\u044b\u043c \u0430\u0440\u0433\u0443\u043c\u0435\u043d\u0442\u043e\u043c \u0444\u0443\u043d\u043a\u0446\u0438\u0438 \u0432\u044b\u0432\u043e\u0434\u0430 \u0434\u043e\u043b\u0436\u0435\u043d \u0431\u044b\u0442\u044c \u043e\u0431\u044a\u0435\u043a\u0442 \u0442\u0438\u043f\u0430 BytesIO \u0438\u043b\u0438 \u0441\u043e\u0432\u043c\u0435\u0441\u0442\u0438\u043c\u044b\u0439 \u0441 \u043d\u0438\u043c \u0431\u0430\u0439\u0442\u043e\u0432\u044b\u0439 \u043a\u043e\u043d\u0442\u0435\u0439\u043d\u0435\u0440\"\n        ) from None\n    OUTPUT_MAP[extension] = func\n</code></pre>"},{"location":"api/contentio/#yass.contentio.serialize","title":"<code>serialize(dataobj: object, format: str, extra_args: dict[str, Any] = {}) -&gt; bytes</code>","text":"<p>summary</p> <p>Parameters:</p> Name Type Description Default <code>dataobj</code> <code>object</code> <p>data object of any type (for example, pandas df, polars df, dict from json, etc.).</p> required <code>format</code> <code>str</code> <p>the target data format in which the object should be written. The required format is determined by the user.</p> required <code>extra_args</code> <code>dict[str, Any]</code> <p>Values of function arguments that need to be bound instead of the default ones. Defaults to {}.</p> <code>{}</code> <p>Raises:</p> Type Description <code>KeyError</code> <p>thrown if there is no registered function of the given format.</p> <p>Returns:</p> Name Type Description <code>bytes</code> <code>bytes</code> <p>Byte representation of content.</p> Source code in <code>src\\yass\\contentio\\contentio.py</code> <pre><code>def serialize(\n    dataobj: object, format: str, extra_args: dict[str, Any] = {}\n) -&gt; bytes:\n    \"\"\"\n    _summary_\n\n    Args:\n        dataobj (object): data object of any type (for example, pandas df, polars df, dict from json, etc.).\n        format (str): the target data format in which the object should be written. The required format is determined by the user.\n        extra_args (dict[str, Any], optional): Values of function arguments that need to be bound instead of the default ones. Defaults to {}.\n\n    Raises:\n        KeyError: thrown if there is no registered function of the given format.\n\n    Returns:\n        bytes: Byte representation of content.\n    \"\"\"\n    byte_buf = BytesIO()\n    func: Callable[[Any, IO, dict], Any] = OUTPUT_MAP[format]\n    func(dataobj, byte_buf, **extra_args)\n    return byte_buf.getvalue()\n</code></pre>"},{"location":"api/helpers/","title":"Utilities functions","text":""},{"location":"api/helpers/#yass.contentio.helpers.update_sign","title":"<code>update_sign(func: Callable, extra_kwargs: dict[str, Any]) -&gt; Callable</code>","text":"<p>Updates the default values \u200b\u200bin the parameters of a given function. Value binding occurs by argument name, regardless of whether positional arguments or keyword are updated. Acts like partial, but allows specific updates of arguments.</p> <p>Parameters:</p> Name Type Description Default <code>func</code> <code>Callable</code> <p>Target function.</p> required <code>extra_kwargs</code> <code>dict[str, Any]</code> <p>A dict of arguments and values \u200b\u200bthat need to be associated with the function.</p> required <p>Returns:</p> Name Type Description <code>Callable</code> <code>Callable</code> <p>Function with updated default arguments.</p> Source code in <code>src\\yass\\contentio\\helpers.py</code> <pre><code>def update_sign(func: Callable, extra_kwargs: dict[str, Any]) -&gt; Callable:\n    \"\"\"\n    Updates the default values \u200b\u200bin the parameters of a given function.\n    Value binding occurs by argument name, regardless of whether\n    positional arguments or keyword are updated.\n    Acts like partial, but allows specific updates of arguments.\n\n    Args:\n        func (Callable): Target function.\n        extra_kwargs (dict[str, Any]): A dict of arguments and values \u200b\u200bthat need to be associated with the function.\n\n    Returns:\n        Callable: Function with updated default arguments.\n    \"\"\"\n    if not extra_kwargs:\n        return func\n    sig: Signature = signature(func)\n    args: list[Any] = []\n    kwargs: dict[str, Any] = {}\n    new_params: list[Parameter] = []\n    for name, param in sig.parameters.items():\n        value: Any = extra_kwargs.get(name, param.default)\n        if param.kind in (\n            Parameter.POSITIONAL_ONLY,\n            Parameter.POSITIONAL_OR_KEYWORD,\n        ):\n            args.append(value)\n        else:\n            kwargs[name] = value\n        new_params.append(param.replace(name=name, default=value))\n    new_sig: Signature = sig.replace(parameters=new_params)\n    if kwdefault := getattr(func, \"__kwdefaults__\", False):\n        kwdefault.update(kwargs)  # type: ignore\n        setattr(func, \"__kwdefaults__\", kwdefault)\n    elif default := getattr(func, \"__defaults__\", False):\n        default = tuple(args)\n        setattr(func, \"__defaults__\", default)\n    elif hasattr(func, \"__signature__\"):\n        func.__signature__ = new_sig\n    else:\n        func = partial(func, *args, **kwargs)\n    return func\n</code></pre>"},{"location":"api/helpers/#yass.contentio.helpers.resolve_annotation","title":"<code>resolve_annotation(annot: Any, annot_owner: Any) -&gt; tuple[type, ...]</code>","text":"<p>Converts the string representation of an annotation to a class. Ignores None annotation.</p> <p>Parameters:</p> Name Type Description Default <code>annot</code> <code>Any</code> <p>The annotation to be converted.</p> required <code>annot_owner</code> <code>Any</code> <p>The object to which the annotation directly belongs. Can be any object containing an annotation.</p> required <p>Raises:</p> Type Description <code>NameError</code> <p>Annotation conversion module not found. The error message indicates the module you are looking for.</p> <p>Returns:</p> Type Description <code>tuple[type, ...]</code> <p>tuple[type, ...] | NoReturn: a tuple with classes corresponding to the annotation (except None).</p> Source code in <code>src\\yass\\contentio\\helpers.py</code> <pre><code>def resolve_annotation(annot: Any, annot_owner: Any) -&gt; tuple[type, ...]:\n    \"\"\"\n    Converts the string representation of an annotation to a class.\n    Ignores None annotation.\n\n    Args:\n        annot (Any): The annotation to be converted.\n        annot_owner (Any): The object to which the annotation directly belongs. Can be any object containing an annotation.\n\n    Raises:\n        NameError: Annotation conversion module not found. The error message indicates the module you are looking for.\n\n    Returns:\n        tuple[type, ...] | NoReturn: a tuple with classes corresponding to the annotation (except None).\n    \"\"\"\n    module_name = (\n        str(annot_owner.__module__)\n        if not isinstance(annot_owner, str)\n        else annot_owner\n    )\n    cnt_split = module_name.count(\".\")\n    if isinstance(annot, str):\n        not_resolved = []\n        search_area = module_name\n        cnt_split = module_name.count(\".\")\n        annotations = annot.split(\"|\")\n        result = []\n        for annot in annotations:\n            loop_cnt = 0\n            while cnt_split &gt;= loop_cnt:\n                annot = annot.strip()\n                try:\n                    import builtins\n                    import io\n                    import pathlib\n                    import typing\n\n                    mod = import_module(search_area)\n                    typeclass = (\n                        getattr(mod, annot, False)\n                        or getattr(builtins, annot, False)\n                        or getattr(io, annot, False)\n                        or getattr(pathlib, annot, False)\n                        or getattr(typing, annot, literal_eval(annot))\n                    )\n                    if typeclass is not None:\n                        result.append(typeclass)\n                    break\n                except Exception:\n                    loop_cnt += 1\n                    search_area = search_area.rsplit(\".\", loop_cnt)[0]\n                    if loop_cnt &gt; cnt_split:\n                        not_resolved.append(annot)\n        if not_resolved:\n            msg = f\"\u0414\u043b\u044f \u0440\u0430\u0437\u0440\u0435\u0448\u0435\u043d\u0438\u044f \u0430\u043d\u043d\u043e\u0442\u0430\u0446\u0438\u0438, \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u043c\u043e\u0439 \u0432 \u043c\u043e\u0434\u0443\u043b\u0435 {module_name}, \u043d\u0435\u043e\u0431\u0445\u043e\u0434\u0438\u043c\u043e \u0438\u043c\u043f\u043e\u0440\u0442\u0438\u0440\u043e\u0432\u0430\u0442\u044c \u0441\u043b\u0435\u0434\u0443\u044e\u0449\u0438\u0435 \u043a\u043b\u0430\u0441\u0441\u044b: {not_resolved}\"\n            raise NameError(msg)\n        return tuple(result)\n    else:\n        return tuple(\n            t for t in [*get_args(annot), get_origin(annot)] if bool(t)\n        )\n</code></pre>"},{"location":"api/helpers/#yass.contentio.helpers.handle_generic","title":"<code>handle_generic(param: Parameter, annotation: Any, target_type: type) -&gt; bool</code>","text":"<p>Checking whether the target type is included in the list using a function argument.</p> <p>Parameters:</p> Name Type Description Default <code>param</code> <code>Parameter</code> <p>A parameter object that represents the target type.</p> required <code>annotation</code> <code>Any</code> <p>A tuple of annotations represented by classes.</p> required <code>target_type</code> <code>type</code> <p>The type to be checked to see if it is included in the arguments.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>Boolean result of the test performed.</p> Source code in <code>src\\yass\\contentio\\helpers.py</code> <pre><code>def handle_generic(\n    param: Parameter, annotation: Any, target_type: type\n) -&gt; bool:\n    \"\"\"\n    Checking whether the target type is included in the list using a function argument.\n\n    Args:\n        param (Parameter): A parameter object that represents the target type.\n        annotation (Any): A tuple of annotations represented by classes.\n        target_type (type): The type to be checked to see if it is included in the arguments.\n\n    Returns:\n        bool: Boolean result of the test performed.\n    \"\"\"\n    if annotation is None or not annotation:\n        return False\n    status: bool = _f(target_type, annotation, param)\n    return status\n</code></pre>"},{"location":"api/helpers/#yass.contentio.helpers.check_input_sig","title":"<code>check_input_sig(func: Callable) -&gt; bool</code>","text":"<p>Validates the signature of the function used to deserialize data. Such a function must take a bytes object as its first parameter.</p> <p>Parameters:</p> Name Type Description Default <code>func</code> <code>Callable</code> <p>Function for deserializing data.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>Boolean result of the test performed.</p> Source code in <code>src\\yass\\contentio\\helpers.py</code> <pre><code>def check_input_sig(func: Callable) -&gt; bool:\n    \"\"\"\n    Validates the signature of the function used to deserialize data.\n    Such a function must take a bytes object as its first parameter.\n\n    Args:\n        func (Callable): Function for deserializing data.\n\n    Returns:\n        bool: Boolean result of the test performed.\n    \"\"\"\n    overloads: Sequence[Callable] = get_overloads(func) or [func]\n    for overload_sign in overloads:\n        sig: Signature = signature(overload_sign)\n        param: Parameter = list(sig.parameters.values())[0]\n        try:\n            annot = get_type_hints(overload_sign)[param.name]\n        except Exception:\n            annot: tuple[type, ...] = resolve_annotation(\n                param.annotation, func\n            )\n        if status := handle_generic(param, annot, bytes):\n            return status\n    return False\n</code></pre>"},{"location":"api/helpers/#yass.contentio.helpers.check_output_sig","title":"<code>check_output_sig(func: Callable) -&gt; bool</code>","text":"<p>Validates a function for data serialization. Such a function must take a byte buffer object (BytesIO) as its second argument.</p> <p>Parameters:</p> Name Type Description Default <code>func</code> <code>Callable</code> <p>Function for serializing data.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>Boolean result of the test performed.</p> Source code in <code>src\\yass\\contentio\\helpers.py</code> <pre><code>def check_output_sig(func: Callable) -&gt; bool:\n    \"\"\"\n    Validates a function for data serialization. Such a function must take a byte buffer object (BytesIO) as its second argument.\n\n    Args:\n        func (Callable): Function for serializing data.\n\n    Returns:\n        bool: Boolean result of the test performed.\n    \"\"\"\n    overloads: Sequence[Callable] = get_overloads(func) or [func]\n    for overload_sign in overloads:\n        sig: Signature = signature(overload_sign)\n        param: Parameter = list(sig.parameters.values())[1]\n        try:\n            annot = get_type_hints(overload_sign)[param.name]\n        except Exception:\n            module_name = str(func.__module__)\n            annot = resolve_annotation(param.annotation, module_name)\n        if status := handle_generic(param, annot, BytesIO):\n            return status\n    return False\n</code></pre>"},{"location":"api/misc_utils/","title":"Various utilities and auxiliary objects","text":""},{"location":"api/misc_utils/#yass.utils.misc.SizeUnit","title":"<code>SizeUnit = Literal['b', 'bytes', 'kb', 'kilobytes', 'mb', 'megabytes', 'gb', 'gigabytes']</code>  <code>module-attribute</code>","text":"<p>Available data size units.</p>"},{"location":"api/misc_utils/#yass.utils.misc.make_async","title":"<code>make_async(cls: type[Any]) -&gt; type</code>","text":"<p>The decorator converts all class methods to an asynchronous version using another decorating function, to_async.</p> <p>Parameters:</p> Name Type Description Default <code>cls</code> <code>type[Any]</code> <p>the class whose methods need to be patched.</p> required <p>Returns:</p> Name Type Description <code>type</code> <code>type</code> <p>a class with methods converted to an asynchronous version.</p> Source code in <code>src\\yass\\utils\\misc.py</code> <pre><code>def make_async(cls: type[Any]) -&gt; type:\n    \"\"\"\n    The decorator converts all class methods to an asynchronous version using another decorating function, to_async.\n\n    Args:\n        cls (type[Any]): the class whose methods need to be patched.\n\n    Returns:\n        type: a class with methods converted to an asynchronous version.\n    \"\"\"\n    members: list[tuple[str, Callable]] = inspect.getmembers(cls, isfunction)\n    for name, meth in members:\n        if not name.startswith(\"__\"):\n            if iscoroutinefunction(meth):\n                continue\n            setattr(cls, name, to_async(meth))  # type: ignore\n    return cls\n</code></pre>"},{"location":"api/misc_utils/#yass.utils.misc.scale_bytes","title":"<code>scale_bytes(sz: int | float, unit: SizeUnit) -&gt; int | float</code>","text":"<p>Scale size in bytes to other size units (eg: \"kb\", \"mb\", \"gb\", \"tb\").</p> Source code in <code>src\\yass\\utils\\misc.py</code> <pre><code>def scale_bytes(sz: int | float, unit: SizeUnit) -&gt; int | float:\n    \"\"\"Scale size in bytes to other size units (eg: \"kb\", \"mb\", \"gb\", \"tb\").\"\"\"\n    if unit in {\"b\", \"bytes\"}:\n        return sz\n    elif unit in {\"kb\", \"kilobytes\"}:\n        return sz / 1024\n    elif unit in {\"mb\", \"megabytes\"}:\n        return sz / 1024**2\n    elif unit in {\"gb\", \"gigabytes\"}:\n        return sz / 1024**3\n    else:\n        raise ValueError(\n            f\"`unit` must be one of {{'b', 'kb', 'mb', 'gb', 'tb'}}, got {unit!r}\"\n        )\n</code></pre>"},{"location":"api/misc_utils/#yass.utils.misc.to_async","title":"<code>to_async(func: Callable[_P, _T]) -&gt; Callable[..., Awaitable[_T]]</code>","text":"<p>Allows a blocking function to be executed asynchronously by wrapping it in a call to to_thread of the asyncio library.</p> <p>Parameters:</p> Name Type Description Default <code>func</code> <code>Callable[_P, _T]</code> <p>function with a blocking call.</p> required <p>Returns:</p> Name Type Description <code>Callable</code> <code>Callable[..., Awaitable[_T]]</code> <p>a function that returns a awaitable object.</p> Source code in <code>src\\yass\\utils\\misc.py</code> <pre><code>def to_async(func: Callable[_P, _T]) -&gt; Callable[..., Awaitable[_T]]:\n    \"\"\"\n    Allows a blocking function to be executed asynchronously by wrapping it in a call to to_thread of the asyncio library.\n\n    Args:\n        func (Callable[_P, _T]): function with a blocking call.\n\n    Returns:\n        Callable: a function that returns a awaitable object.\n    \"\"\"\n\n    @wraps(func)\n    def wrapped(*args: _P.args, **kwargs: _P.kwargs) -&gt; Awaitable[_T]:\n        return to_thread(func, *args, **kwargs)\n\n    return wrapped\n</code></pre>"},{"location":"api/scheduling/","title":"Implementations","text":""},{"location":"api/scheduling/#core-classes","title":"Core classes","text":""},{"location":"api/scheduling/#yass.scheduling.limits.CountLimit","title":"<code>CountLimit(storage: BaseBufferableStorage, capacity: int)</code>","text":"<p>             Bases: <code>BaseLimit</code></p> <p>A limit class that controls the number of objects in buffers.</p> <p>Parameters:</p> Name Type Description Default <code>storage</code> <code>BaseBufferableStorage</code> <p>a storage facility whose status is monitored.</p> required <code>capacity</code> <code>int</code> <p>the limit on the number of objects in the buffer.</p> required Source code in <code>src\\yass\\scheduling\\limits.py</code> <pre><code>def __init__(self, storage: BaseBufferableStorage, capacity: int):\n    \"\"\"\n    A limit class that controls the number of objects in buffers.\n\n    Args:\n        storage (BaseBufferableStorage): a storage facility whose status is monitored.\n        capacity (int): the limit on the number of objects in the buffer.\n    \"\"\"\n    self.storage: BaseBufferableStorage = storage\n    self.capacity: int = capacity\n</code></pre>"},{"location":"api/scheduling/#yass.scheduling.limits.MemoryLimit","title":"<code>MemoryLimit(storage: BaseBufferableStorage, capacity: int | float)</code>","text":"<p>             Bases: <code>BaseLimit</code></p> <p>A limit class that controls the amount of memory occupied by buffers.</p> <p>Parameters:</p> Name Type Description Default <code>storage</code> <code>BaseBufferableStorage</code> <p>a storage facility whose status is monitored.</p> required <code>capacity</code> <code>int | float</code> <p>memory threshold in megabytes.</p> required Source code in <code>src\\yass\\scheduling\\limits.py</code> <pre><code>def __init__(self, storage: BaseBufferableStorage, capacity: int | float):\n    \"\"\"\n    A limit class that controls the amount of memory occupied by buffers.\n\n    Args:\n        storage (BaseBufferableStorage): a storage facility whose status is monitored.\n        capacity (int | float): memory threshold in megabytes.\n    \"\"\"\n    self.storage: BaseBufferableStorage = storage\n    self.capacity: int | float = capacity\n</code></pre>"},{"location":"api/scheduling/#yass.scheduling.limits.TimeLimit","title":"<code>TimeLimit(storage: BaseBufferableStorage, capacity: int)</code>","text":"<p>             Bases: <code>BaseLimit</code></p> <p>A limit class that controls how long data remains in the buffer.</p> <p>Parameters:</p> Name Type Description Default <code>storage</code> <code>BaseBufferableStorage</code> <p>a storage facility whose status is monitored.</p> required <code>capacity</code> <code>int</code> <p>time in seconds.</p> required Source code in <code>src\\yass\\scheduling\\limits.py</code> <pre><code>def __init__(self, storage: BaseBufferableStorage, capacity: int):\n    self.storage: BaseBufferableStorage = storage\n    self.capacity = timedelta(seconds=capacity)\n</code></pre>"},{"location":"api/scheduling/#yass.scheduling.limits.UnableBufferize","title":"<code>UnableBufferize</code>","text":"<p>             Bases: <code>BaseLimit</code></p> <p>Special plug. Essentially disables data buffering, forcing the storage class to continuously write data to the backend. Its use can negatively impact performance as it significantly increases the amount of I/O and more often blocks memory buffers until the data is uploaded to the backend.</p>"},{"location":"api/scheduling/#yass.scheduling.timeinterval.AlwaysRun","title":"<code>AlwaysRun</code>","text":"<p>             Bases: <code>ActionCondition</code></p> <p>A special class that makes the collection of data from a resource constantly active.</p>"},{"location":"api/scheduling/#yass.scheduling.timeinterval.DailyInterval","title":"<code>DailyInterval(day_interval: int, start_time: str, end_time: str, launch: datetime | str | None = None)</code>","text":"<p>Helper class for checking daily time intervals. Used in the TimeCondition class.</p> <p>Parameters:</p> Name Type Description Default <code>day_interval</code> <code>int</code> <p>activity interval, in days. If you want the arrival of                 the required time to be checked every day, you need to                 specify 1 in this parameter; to check the condition every                 two days 2 and so on.</p> required <code>start_time</code> <code>str</code> <p>start of the check time interval. Indicated in a form that             allows you to recognize the time, for example, \u201c10:00\u201d, \u201c10.00\u201d, \u201c10-00\u201d and so on.</p> required <code>end_time</code> <code>str</code> <p>end of the check time interval. It is assumed that after this time threshold is overcome,             the starting point will shift to the next calendar interval.</p> required <code>launch</code> <code>datetime | str | None</code> <p>The starting point for checking the time interval as             a recognizable date or date and time (for example, \"10/20/2024 10:00\"). If not specified,             the start of waiting for the required time starts immediately. If you need to delay             the occurrence of a control event, you need to specify a future date. If an urgent             start of data collection is required, then a past date must be specified. Defaults to None.</p> <code>None</code> Source code in <code>src\\yass\\scheduling\\timeinterval.py</code> <pre><code>def __init__(\n    self,\n    day_interval: int,\n    start_time: str,\n    end_time: str,\n    launch: datetime | str | None = None,\n):\n    self._interval: int = day_interval\n    self.start: time = dateparser.parse(start_time).time()  # type:ignore\n    self.end: time = dateparser.parse(end_time).time()  # type: ignore\n    self.launch: datetime = (\n        datetime.combine(date=datetime.now().date(), time=self.start)\n        if launch is None\n        else dateparser.parse(launch)  # type: ignore\n    )\n</code></pre>"},{"location":"api/scheduling/#yass.scheduling.timeinterval.DailyInterval.__bool__","title":"<code>__bool__() -&gt; bool</code>","text":"<p>The method is overridden and compares the current date and time, the control date and time, and the end time of the activity interval.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>returns True if the current time exceeds the control threshold and is also included in the active time interval.</p> Source code in <code>src\\yass\\scheduling\\timeinterval.py</code> <pre><code>def __bool__(self) -&gt; bool:\n    \"\"\"\n    The method is overridden and compares the current date and time, the control date and\n    time, and the end time of the activity interval.\n\n    Returns:\n        bool: returns True if the current time exceeds the control threshold and is also included in the active time interval.\n    \"\"\"\n    return (\n        datetime.now()\n        &gt;= self.launch\n        &lt; datetime.combine(date=self.launch.date(), time=self.end)\n    )\n</code></pre>"},{"location":"api/scheduling/#yass.scheduling.timeinterval.DailyInterval.next_launch","title":"<code>next_launch() -&gt; None</code>","text":"<p>The method determines the next key date according to the specified daily interval.</p> Source code in <code>src\\yass\\scheduling\\timeinterval.py</code> <pre><code>def next_launch(self) -&gt; None:\n    \"\"\"\n    The method determines the next key date according to the specified daily interval.\n    \"\"\"\n    next_date: date = self.launch.date() + timedelta(days=self._interval)\n    self.launch = datetime.combine(date=next_date, time=self.start)\n</code></pre>"},{"location":"api/scheduling/#yass.scheduling.timeinterval.DailyInterval.shift_launch","title":"<code>shift_launch(frequency: int | float) -&gt; None</code>","text":"<p>The method shifts the next launch time by a specified interval in hours. Also, in this method, the next time interval is aligned in the case of starting from the \u201cpast\u201d time. The lag in this case is determined in integer form.</p> <p>Parameters:</p> Name Type Description Default <code>frequency</code> <code>float</code> <p>start time shift interval.</p> required Source code in <code>src\\yass\\scheduling\\timeinterval.py</code> <pre><code>def shift_launch(self, frequency: int | float) -&gt; None:\n    \"\"\"\n    The method shifts the next launch time by a specified interval in hours.\n    Also, in this method, the next time interval is aligned in the case of starting from the \u201cpast\u201d time.\n    The lag in this case is determined in integer form.\n\n    Args:\n        frequency (float): start time shift interval.\n    \"\"\"\n    hours = timedelta(hours=1)\n    # \u0435\u0441\u043b\u0438 \u043c\u044b \u0437\u0430\u043f\u0443\u0441\u043a\u0430\u0435\u043c \u0441\u043a\u0440\u0438\u043f\u0442 \u0441 \u0433\u043b\u0443\u0431\u043e\u043a\u0438\u043c \u043b\u0430\u0433\u043e\u043c (\u043d\u0430\u043f\u0440\u0438\u043c\u0435\u0440, \u0432 12:00 \u043f\u0440\u0438 \u0437\u0430\u0434\u0430\u043d\u043d\u043e\u043c \u0441\u0442\u0430\u0440\u0442\u0435 \u0432 9:00),\n    # \u0442\u043e \u043d\u0430\u043c \u043d\u0443\u0436\u043d\u043e \"\u0432\u044b\u0440\u043e\u0432\u043d\u044f\u0442\u044c\" \u0432\u0440\u0435\u043c\u044f \u0441\u043b\u0435\u0434\u0443\u044e\u0449\u0435\u0433\u043e \u0437\u0430\u043f\u0443\u0441\u043a\u0430 \u0432\u043e \u0438\u0437\u0431\u0435\u0436\u0430\u043d\u0438\u0435 \u0447\u0435\u0440\u0435\u0434\u044b \u043b\u043e\u0436\u043d\u044b\u0445 \u0437\u0430\u043f\u0443\u0441\u043a\u043e\u0432\n    lag: int = (datetime.now() - self.launch) // hours\n    frequency = lag + frequency if lag &gt; frequency else frequency\n    self.launch += timedelta(hours=frequency)\n</code></pre>"},{"location":"api/scheduling/#yass.scheduling.timeinterval.TimeCondition","title":"<code>TimeCondition</code>  <code>dataclass</code>","text":"<p>             Bases: <code>ActionCondition</code></p>"},{"location":"api/scheduling/#yass.scheduling.timeinterval.TimeCondition.is_able","title":"<code>is_able() -&gt; bool</code>","text":"<p>The method checks whether a checkpoint (a specified timestamp) has been reached.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>returns True if the checkpoint has arrived.</p> Source code in <code>src\\yass\\scheduling\\timeinterval.py</code> <pre><code>def is_able(self) -&gt; bool:\n    \"\"\"\n    The method checks whether a checkpoint (a specified timestamp) has been reached.\n\n    Returns:\n        bool: returns True if the checkpoint has arrived.\n    \"\"\"\n    print(\"Start check condition\")\n    print(f\"Next launch is {self.schedule_interval.launch}\")\n    return bool(self.schedule_interval)\n</code></pre>"},{"location":"api/scheduling/#yass.scheduling.timeinterval.TimeCondition.pending","title":"<code>pending() -&gt; None</code>  <code>async</code>","text":"<p>The method initializes waiting for a reference timestamp. If the checkpoint is not reached, the class's utility method determines the size of the delta between the current time and the checkpoint and starts waiting for the specified delta. Upon reaching it, the method unlocks further execution.</p> Source code in <code>src\\yass\\scheduling\\timeinterval.py</code> <pre><code>async def pending(self) -&gt; None:\n    \"\"\"\n    The method initializes waiting for a reference timestamp.\n    If the checkpoint is not reached, the class's utility method determines\n    the size of the delta between the current time and the checkpoint and\n    starts waiting for the specified delta.\n    Upon reaching it, the method unlocks further execution.\n    \"\"\"\n    while not self.is_able():\n        print(\"Sleeping\")\n        delta: timedelta = self._get_delay()\n        print(f\"Condition was sleep above {delta} seconds\")\n        await sleep(delta.total_seconds())\n    self.reset()\n</code></pre>"},{"location":"api/scheduling/#yass.scheduling.timeinterval.TimeCondition.reset","title":"<code>reset() -&gt; None</code>","text":"<p>The method shifts the control point by frequency and checks whether the new value is within the specified activity range. If not, then the next scan launch is scheduled for the next period.</p> Source code in <code>src\\yass\\scheduling\\timeinterval.py</code> <pre><code>def reset(self) -&gt; None:\n    \"\"\"\n    The method shifts the control point by frequency and checks whether the new value is\n    within the specified activity range. If not, then the next scan launch is scheduled\n    for the next period.\n    \"\"\"\n    self.schedule_interval.shift_launch(self.frequency)\n    # TODO: \u043c\u043e\u0436\u043d\u043e \u0441\u043e\u043a\u0440\u0430\u0442\u0438\u0442\u044c \u043f\u0440\u043e\u0432\u0435\u0440\u043a\u0443 \u0434\u043e \u0432\u044b\u0437\u043e\u0432\u0430 is_able \u0438 \u043f\u0440\u043e\u0432\u0435\u0440\u043a\u0438 \u043d\u0430 one_run - \u043d\u0438\u0436\u0435 \u0443\u0441\u043b\u043e\u0432\u0438\u0435 \u043f\u043e \u0441\u043c\u044b\u0441\u043b\u0443 \u0442\u0430\u043a\u043e\u0435 \u0441\u0430\u043c\u043e\u0435\n    if (\n        self.schedule_interval.end &lt; self.schedule_interval.launch.time()\n        or self._one_run\n    ):\n        self.schedule_interval.next_launch()\n</code></pre>"},{"location":"api/scheduling/#yass.scheduling.timeinterval.WeekdayInterval","title":"<code>WeekdayInterval(weekday_interval: WeekDaysType, start_time: str, end_time: str, launch: datetime | str | None = None)</code>","text":"<p>Helper class for checking time intervals by day of the week. Used in the TimeCondition class.</p> <p>Parameters:</p> Name Type Description Default <code>weekday_interval</code> <code>WeekDaysType</code> <p>check interval in the form of a tuple with numbers of days of the week.                             The days of the week are specified in the order prescribed by ISO 8601.                             For example, if you need to control time on Mondays, Wednesdays and Fridays,                             then the tuple should look like (1,3,5). The maximum value for days of the week                             is seven. The order of the weekday numbers is not important.</p> required <code>start_time</code> <code>str</code> <p>start of the check time interval. Indicated in a form that             allows you to recognize the time, for example, \u201c10:00\u201d, \u201c10.00\u201d, \u201c10-00\u201d and so on.</p> required <code>end_time</code> <code>str</code> <p>end of the check time interval. It is assumed that after this time threshold is overcome,             the starting point will shift to the next calendar interval.</p> required <code>launch</code> <code>datetime | str | None</code> <p>The starting point for checking the time interval as         a recognizable date or date and time (for example, \"10/20/2024 10:00\"). If not specified,         the start of waiting for the required time starts immediately. If you need to delay         the occurrence of a control event, you need to specify a future date. If an urgent         start of data collection is required, then a past date must be specified. Defaults to None.</p> <code>None</code> Source code in <code>src\\yass\\scheduling\\timeinterval.py</code> <pre><code>def __init__(\n    self,\n    weekday_interval: WeekDaysType,\n    start_time: str,\n    end_time: str,\n    launch: datetime | str | None = None,\n):\n    \"\"\"\n    Helper class for checking time intervals by day of the week. Used in the TimeCondition class.\n\n    Args:\n        weekday_interval (WeekDaysType): check interval in the form of a tuple with numbers of days of the week.\n                                        The days of the week are specified in the order prescribed by ISO 8601.\n                                        For example, if you need to control time on Mondays, Wednesdays and Fridays,\n                                        then the tuple should look like (1,3,5). The maximum value for days of the week\n                                        is seven. The order of the weekday numbers is not important.\n        start_time (str): start of the check time interval. Indicated in a form that\n                        allows you to recognize the time, for example, \u201c10:00\u201d, \u201c10.00\u201d, \u201c10-00\u201d and so on.\n        end_time (str): end of the check time interval. It is assumed that after this time threshold is overcome,\n                        the starting point will shift to the next calendar interval.\n        launch (datetime | str | None, optional): The starting point for checking the time interval as\n                    a recognizable date or date and time (for example, \"10/20/2024 10:00\"). If not specified,\n                    the start of waiting for the required time starts immediately. If you need to delay\n                    the occurrence of a control event, you need to specify a future date. If an urgent\n                    start of data collection is required, then a past date must be specified. Defaults to None.\n    \"\"\"\n    self._interval = weekday_interval\n    self._weekday_it = cycle(set(sorted(weekday_interval)))\n    self.current_weekday: AllowedWeekDays = next(self._weekday_it)\n    self.start: time = dateparser.parse(start_time).time()  # type: ignore\n    self.end: time = dateparser.parse(end_time).time()  # type: ignore\n    self.launch: datetime = (\n        datetime.combine(date=datetime.now().date(), time=self.start)\n        if launch is None\n        else dateparser.parse(launch)  # type: ignore\n    )\n</code></pre>"},{"location":"api/scheduling/#yass.scheduling.timeinterval.WeekdayInterval.__bool__","title":"<code>__bool__() -&gt; bool</code>","text":"<p>The method is overridden and compares the current date and time, the control date and time, and the end time of the activity interval.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>returns True if the current time exceeds the control threshold and is also included in the active time interval.</p> Source code in <code>src\\yass\\scheduling\\timeinterval.py</code> <pre><code>def __bool__(self) -&gt; bool:\n    \"\"\"\n    The method is overridden and compares the current date and time, the control date and\n    time, and the end time of the activity interval.\n\n    Returns:\n        bool: returns True if the current time exceeds the control threshold and is also included in the active time interval.\n    \"\"\"\n    return (\n        datetime.now()\n        &gt;= self.launch\n        &lt; datetime.combine(date=self.launch.date(), time=self.end)\n    )\n</code></pre>"},{"location":"api/scheduling/#yass.scheduling.timeinterval.WeekdayInterval.next_launch","title":"<code>next_launch() -&gt; None</code>","text":"<p>The method determines the next key date according to the specified period.</p> Source code in <code>src\\yass\\scheduling\\timeinterval.py</code> <pre><code>def next_launch(self) -&gt; None:\n    \"\"\"\n    The method determines the next key date according to the specified period.\n    \"\"\"\n    interval = abs(next(self._weekday_it) - self.current_weekday)\n    next_date = self.launch.date() + timedelta(days=interval)\n    self.launch = datetime.combine(date=next_date, time=self.start)\n</code></pre>"},{"location":"api/scheduling/#yass.scheduling.timeinterval.WeekdayInterval.shift_launch","title":"<code>shift_launch(frequency: int | float) -&gt; None</code>","text":"<p>The method shifts the next launch time by a specified interval in hours. Also, in this method, the next time interval is aligned in the case of starting from the \u201cpast\u201d time. The lag in this case is determined in integer form.</p> <p>Parameters:</p> Name Type Description Default <code>frequency</code> <code>float</code> <p>start time shift interval.</p> required Source code in <code>src\\yass\\scheduling\\timeinterval.py</code> <pre><code>def shift_launch(self, frequency: int | float) -&gt; None:\n    \"\"\"\n    The method shifts the next launch time by a specified interval in hours.\n    Also, in this method, the next time interval is aligned in the case of starting from the \u201cpast\u201d time.\n    The lag in this case is determined in integer form.\n\n    Args:\n        frequency (float): start time shift interval.\n    \"\"\"\n    hours = timedelta(hours=1)\n    lag = (datetime.now() - self.launch) // hours\n    frequency = lag + frequency if lag &gt; frequency else frequency\n    self.launch += timedelta(hours=frequency)\n</code></pre>"},{"location":"api/scheduling/#service-classes-and-utilities","title":"Service classes and utilities","text":""},{"location":"api/scheduling/#yass.scheduling.limits.get_allowed_limits","title":"<code>get_allowed_limits() -&gt; list[tuple[str, BaseLimit]]</code>","text":"<p>The function returns all currently available limit classes as a container.</p> <p>Returns:</p> Name Type Description <code>list</code> <code>tuple[str, BaseLimit]</code> <p>list of tuples with pairs limit name - limit class object.</p> Source code in <code>src\\yass\\scheduling\\limits.py</code> <pre><code>def get_allowed_limits() -&gt; list[tuple[str, BaseLimit]]:\n    \"\"\"\n    The function returns all currently available limit classes as a container.\n\n    Returns:\n        list (tuple[str, BaseLimit]): list of tuples with pairs limit name - limit class object.\n    \"\"\"\n    return list((k, v) for k, v in _LIMIT_MAP.items())\n</code></pre>"},{"location":"api/scheduling/#yass.scheduling.limits.limit","title":"<code>limit(limit_type: str) -&gt; Callable[[type[BaseLimit]], type[BaseLimit]]</code>","text":"<p>A decorator for registering limit classes in the corresponding factory.</p> <p>Parameters:</p> Name Type Description Default <code>limit_type</code> <code>str</code> <p>name of the limit. It is highly desirable that it reflects the real meaning of the registered limit class.</p> required <p>Returns:</p> Name Type Description <code>Callable</code> <code>Callable[[type[BaseLimit]], type[BaseLimit]]</code> <p>returns the registration function. Based on the results of the entire chain of calls,     the specified function will return the registered class without changes.</p> Source code in <code>src\\yass\\scheduling\\limits.py</code> <pre><code>def limit(limit_type: str) -&gt; Callable[[type[BaseLimit]], type[BaseLimit]]:\n    \"\"\"\n    A decorator for registering limit classes in the corresponding factory.\n\n    Args:\n        limit_type (str): name of the limit. It is highly desirable that it reflects the real meaning of the registered limit class.\n\n    Returns:\n        Callable: returns the registration function. Based on the results of the entire chain of calls,\n                the specified function will return the registered class without changes.\n    \"\"\"\n\n    def registred_limit(cls: type[BaseLimit]) -&gt; type[BaseLimit]:\n        _LIMIT_MAP[limit_type] = cls\n        return cls\n\n    return registred_limit\n</code></pre>"},{"location":"api/scheduling/#yass.scheduling.limits.setup_limit","title":"<code>setup_limit(limit_type: str, capacity: Any, storage: BaseBufferableStorage) -&gt; BaseLimit</code>","text":"<p>Factory function that returns an instance of the limits class.</p> <p>Parameters:</p> Name Type Description Default <code>limit_type</code> <code>str</code> <p>limit type.</p> required <code>capacity</code> <code>Any</code> <p>volume limit.</p> required <code>storage</code> <code>BaseBufferableStorage</code> <p>the storage to which the limit will be associated.</p> required <p>Returns:</p> Name Type Description <code>BaseLimit</code> <code>BaseLimit</code> <p>instance of the limit class of the selected type.</p> Source code in <code>src\\yass\\scheduling\\limits.py</code> <pre><code>def setup_limit(\n    limit_type: str, capacity: Any, storage: BaseBufferableStorage\n) -&gt; BaseLimit:\n    \"\"\"\n    Factory function that returns an instance of the limits class.\n\n    Args:\n        limit_type (str): limit type.\n        capacity (Any): volume limit.\n        storage (BaseBufferableStorage): the storage to which the limit will be associated.\n\n    Returns:\n        BaseLimit: instance of the limit class of the selected type.\n    \"\"\"\n    limit_instance: BaseLimit = _LIMIT_MAP[limit_type](storage, capacity)\n    return limit_instance\n</code></pre>"},{"location":"api/scheduling/#types-constants-and-enums","title":"Types, constants and enums","text":""},{"location":"api/scheduling/#yass.scheduling.timeinterval.AllowedWeekDays","title":"<code>AllowedWeekDays = Literal[1, 2, 3, 4, 5, 6, 7]</code>  <code>module-attribute</code>","text":"<p>The type of valid values \u200b\u200bfor the days of the week.</p>"},{"location":"api/scheduling/#yass.scheduling.timeinterval.WeekDaysType","title":"<code>WeekDaysType = Iterable[AllowedWeekDays]</code>  <code>module-attribute</code>","text":"<p>Type of container with digital designation of days of the week.</p>"},{"location":"api/yass/","title":"Yass module","text":""},{"location":"api/yass/#yass.EntryPoint","title":"<code>EntryPoint</code>  <code>dataclass</code>","text":""},{"location":"api/yass/#yass.EntryPoint.debug_mode","title":"<code>debug_mode: bool = field(init=False, default=False)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The main class responsible for configuring, running and controlling  the application. Provides methods for registering resources and stores.</p> <p>Parameters:</p> Name Type Description Default <code>lookup_interval</code> <code>int</code> <p>the interval in seconds at which task completion is checked.</p> required <code>registred_resources</code> <code>list</code> <p>list of registered resources. Resources store data about requests, for each of which a                         data collector is created.</p> required <code>debug_mode</code> <code>bool</code> <p>Debug mode indicator. Default is False.</p> required"},{"location":"api/yass/#yass.EntryPoint.define_resource","title":"<code>define_resource(*, resource_type: Literal['api'], url: str) -&gt; ApiResource</code>","text":"<p>The method allows you to create and register resources. At the moment, only the resource API implementation is available.</p> <p>Parameters:</p> Name Type Description Default <code>resource_type</code> <code>Literal[&amp;quot;api&amp;quot;]</code> <p>resource type. At the moment, only the API resource is available.</p> required <code>url</code> <code>str</code> <p>As a rule, this is a full-fledged link without dynamic parts of the URL address.</p> required <p>Returns:</p> Name Type Description <code>ApiResource</code> <code>ApiResource</code> <p>instance of api resource.</p> Source code in <code>src\\yass\\yass.py</code> <pre><code>def define_resource(\n    self, *, resource_type: Literal[\"api\"], url: str\n) -&gt; ApiResource:\n    \"\"\"\n    The method allows you to create and register resources. At the moment, only the resource API implementation is available.\n\n    Args:\n        resource_type (Literal[&amp;quot;api&amp;quot;]): resource type. At the moment, only the API resource is available.\n        url (str): As a rule, this is a full-fledged link without dynamic parts of the URL address.\n\n    Returns:\n        ApiResource: instance of api resource.\n    \"\"\"\n    impl = BaseResource.available_impl()[resource_type]\n    instance = impl(url)\n    self.registred_resources.append(instance)\n    return instance\n</code></pre>"},{"location":"api/yass/#yass.EntryPoint.define_storage","title":"<code>define_storage(*, storage_type: Literal['blob']) -&gt; FsBlobStorage</code>","text":"<p>The method creates a store. The storage configuration (limits, creds, and so on) is carried out after creating an instance of the class. At the moment, only storage with file system engines is available.</p> <p>Parameters:</p> Name Type Description Default <code>storage_type</code> <code>Literal[blob]</code> <p>storage type.</p> required <p>Returns:</p> Name Type Description <code>FsBlobStorage</code> <code>FsBlobStorage</code> <p>FsBlobStorage instance.</p> Source code in <code>src\\yass\\yass.py</code> <pre><code>def define_storage(\n    self, *, storage_type: Literal[\"blob\"]\n) -&gt; FsBlobStorage:\n    \"\"\"\n    The method creates a store. The storage configuration (limits, creds, and so on) is carried out after creating\n    an instance of the class.\n    At the moment, only storage with file system engines is available.\n\n    Args:\n        storage_type (Literal[blob]): storage type.\n\n    Returns:\n        FsBlobStorage: FsBlobStorage instance.\n    \"\"\"\n    impl = BaseBufferableStorage.available_impl()[storage_type]\n    instance = impl()\n    return instance\n</code></pre>"},{"location":"api/yass/#yass.EntryPoint.run","title":"<code>run(*, debug: bool = False) -&gt; None</code>","text":"<p>Method for launching the application. After calling it, data collectors are created and launched.</p> <p>Parameters:</p> Name Type Description Default <code>debug</code> <code>bool</code> <p>if True, then the application will start in debug mode and write a detailed log.                     Important! At the moment, logging is not implemented. Defaults to False.</p> <code>False</code> Source code in <code>src\\yass\\yass.py</code> <pre><code>def run(self, *, debug: bool = False) -&gt; None:\n    \"\"\"\n    Method for launching the application. After calling it, data collectors are created and launched.\n\n    Args:\n        debug (bool, optional): if True, then the application will start in debug mode and write a detailed log.\n                                Important! At the moment, logging is not implemented. Defaults to False.\n    \"\"\"\n    self.debug_mode = debug\n    threaded_loop = Thread(target=self._run_async)\n    threaded_loop.start()\n    threaded_loop.join()\n</code></pre>"}]}